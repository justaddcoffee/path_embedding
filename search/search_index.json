{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"path-embedding","text":"<p>Classifier that uses embeddings to find useful paths between drugs and disease</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Usage Guide - How to train and evaluate the classifier</li> <li>Design Document - Detailed architecture and design decisions</li> <li>Implementation Plan - Complete task breakdown</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>This tool uses large language model embeddings (OpenAI) to classify whether mechanistic paths between drugs and diseases are biologically plausible.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Embedding-based classification: Leverages OpenAI text-embedding-3-small to capture semantic meaning</li> <li>Negative sampling: Cross-disease shuffling with type matching creates challenging negatives</li> <li>Indication-level split: Prevents data leakage by splitting at drug-disease pair level</li> <li>Comprehensive evaluation: Standard metrics (accuracy, precision, recall, F1, ROC-AUC)</li> <li>Extensible design: Ready for KGX format and other knowledge graphs</li> </ul>"},{"location":"#training-pipeline","title":"Training Pipeline","text":"<pre><code>DrugMechDB YAML \u2192 Extract Paths \u2192 Generate Negatives \u2192 Convert to Text \u2192\nEmbed (OpenAI) \u2192 Train/Test Split \u2192 Train Random Forest \u2192 Evaluate \u2192 Save Model\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<pre><code># Install dependencies\nuv sync --group dev\n\n# Train classifier\nuv run path-embedding train \\\n  --data data/drugmechdb.yaml \\\n  --output models/classifier.pkl \\\n  --api-key-path ~/.openai.key\n\n# Run tests\nuv run pytest tests/ -v\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Auto-generated schema documentation</li> </ul>"},{"location":"about/","title":"About path-embedding","text":"<p>Classifier that uses embeddings to find useful paths between drugs and disease</p>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide explains how to use the path-embedding classifier for training and evaluation.</p>"},{"location":"usage/#installation","title":"Installation","text":"<p>Install the project and its dependencies:</p> <pre><code>cd path_embedding\nuv sync --group dev\n</code></pre>"},{"location":"usage/#command-line-interface","title":"Command Line Interface","text":""},{"location":"usage/#training-the-classifier","title":"Training the Classifier","text":"<p>The main command is <code>train</code>, which orchestrates the entire training pipeline:</p> <pre><code>uv run path-embedding train \\\n  --data data/drugmechdb.yaml \\\n  --output models/my_classifier.pkl \\\n  --api-key-path /path/to/openai.key \\\n  --test-size 0.2 \\\n  --max-paths-per-indication 10 \\\n  --random-seed 42\n</code></pre>"},{"location":"usage/#options","title":"Options","text":"<ul> <li><code>--data</code> (required): Path to DrugMechDB YAML file containing drug-disease mechanistic paths</li> <li><code>--output</code> (required): Path where to save the trained model (.pkl)</li> <li><code>--api-key-path</code>: Path to file containing OpenAI API key (default: <code>/Users/jtr4v/openai.key.another</code>)</li> <li><code>--test-size</code>: Fraction of data for test set (default: 0.2)</li> <li><code>--max-paths-per-indication</code>: Maximum paths to extract per indication (default: 10)</li> <li><code>--random-seed</code>: Random seed for reproducibility (default: 42)</li> </ul>"},{"location":"usage/#help","title":"Help","text":"<p>Get detailed help for the train command:</p> <pre><code>uv run path-embedding train --help\n</code></pre>"},{"location":"usage/#training-pipeline","title":"Training Pipeline","text":"<p>The <code>train</code> command executes the following steps:</p> <ol> <li>Data Loading: Loads DrugMechDB YAML file with multigraph representations</li> <li>Path Extraction: Extracts all simple paths from drug to disease nodes</li> <li>Negative Sampling: Generates negative examples via cross-disease shuffling</li> <li>Train/Test Split: Splits at indication level to prevent data leakage</li> <li>Embedding Generation: Converts paths to text and generates OpenAI embeddings</li> <li>Model Training: Trains Random Forest classifier on embeddings</li> <li>Evaluation: Evaluates on test set with standard metrics</li> <li>Model Saving: Saves trained model to disk</li> </ol>"},{"location":"usage/#example-workflow","title":"Example Workflow","text":""},{"location":"usage/#step-1-prepare-data","title":"Step 1: Prepare Data","text":"<p>Place your DrugMechDB YAML file in the <code>data/</code> directory:</p> <pre><code># Copy your data file\ncp /path/to/drugmechdb.yaml data/\n</code></pre>"},{"location":"usage/#step-2-set-up-api-key","title":"Step 2: Set Up API Key","text":"<p>Create a file with your OpenAI API key:</p> <pre><code>echo \"sk-your-api-key-here\" &gt; ~/.openai.key\nchmod 600 ~/.openai.key\n</code></pre>"},{"location":"usage/#step-3-train-model","title":"Step 3: Train Model","text":"<p>Run the training pipeline:</p> <pre><code>uv run path-embedding train \\\n  --data data/drugmechdb.yaml \\\n  --output models/classifier.pkl \\\n  --api-key-path ~/.openai.key\n</code></pre>"},{"location":"usage/#step-4-check-results","title":"Step 4: Check Results","text":"<p>The training output will show:</p> <pre><code>Loading DrugMechDB data...\nLoaded 50 indications\nExtracting paths from multigraphs...\nExtracted 150 positive paths\nGenerating negative examples...\nGenerated 150 negative paths\n...\nTraining Random Forest classifier...\nEvaluating on test set...\n\n=== Classification Report ===\n              precision    recall  f1-score   support\n   Implausible       0.85      0.82      0.84        30\n     Plausible       0.88      0.90      0.89        30\n...\n\n=== Metrics Summary ===\naccuracy: 0.8667\nprecision: 0.8667\nrecall: 0.8667\nf1: 0.8667\nroc_auc: 0.9289\n</code></pre>"},{"location":"usage/#testing","title":"Testing","text":"<p>Run the test suite:</p> <pre><code># All tests with type checking and formatting\nuv run pytest tests/ -v\n</code></pre> <p>Run specific test categories:</p> <pre><code># Data loading tests\nuv run pytest tests/test_drugmechdb.py -v\n\n# Classifier tests\nuv run pytest tests/test_classifier.py -v\n\n# Evaluation tests\nuv run pytest tests/test_evaluation.py -v\n\n# CLI integration tests\nuv run pytest tests/test_cli.py -v\n</code></pre> <p>Include doctests:</p> <pre><code>uv run pytest tests/ --doctest-modules -v\n</code></pre>"},{"location":"usage/#type-checking","title":"Type Checking","text":"<p>Run mypy for type checking:</p> <pre><code>uv run mypy src tests\n</code></pre>"},{"location":"usage/#code-formatting","title":"Code Formatting","text":"<p>Check code style with ruff:</p> <pre><code>uv run ruff check .\n</code></pre>"},{"location":"usage/#architecture-overview","title":"Architecture Overview","text":""},{"location":"usage/#core-components","title":"Core Components","text":"<ul> <li>Data Models (<code>src/path_embedding/datamodel/types.py</code>): Node, Edge, Path data structures</li> <li>Data Loading (<code>src/path_embedding/data/</code>): DrugMechDB and KGX loaders</li> <li>Path Extraction (<code>src/path_embedding/utils/path_extraction.py</code>): NetworkX multigraph operations</li> <li>Embedding (<code>src/path_embedding/embedding/</code>): Text conversion and OpenAI API integration</li> <li>Classifier (<code>src/path_embedding/model/</code>): Training, evaluation, and data splitting</li> <li>CLI (<code>src/path_embedding/cli.py</code>): Command-line interface</li> </ul>"},{"location":"usage/#data-flow","title":"Data Flow","text":"<pre><code>DrugMechDB YAML\n    \u2193\nLoad Indications\n    \u2193\nBuild MultiDiGraphs\n    \u2193\nExtract Paths\n    \u2193\nGenerate Negative Paths\n    \u2193\nConvert to Text\n    \u2193\nGenerate Embeddings (OpenAI)\n    \u2193\nTrain/Test Split (by Indication)\n    \u2193\nTrain Random Forest\n    \u2193\nEvaluate\n    \u2193\nSave Model\n</code></pre>"},{"location":"usage/#performance-considerations","title":"Performance Considerations","text":""},{"location":"usage/#api-costs","title":"API Costs","text":"<p>The training pipeline makes real API calls to OpenAI for embedding generation. Costs scale with: - Number of paths - Embedding model (text-embedding-3-small is default)</p> <p>To minimize costs during development: - Use small datasets or sample data - Set <code>--max-paths-per-indication 1</code> to extract only one path per drug-disease pair - Use <code>tests/data/sample_drugmechdb.yaml</code> (2 indications)</p>"},{"location":"usage/#computation-time","title":"Computation Time","text":"<p>Training time depends on: - Dataset size (number of paths) - API response times - Random Forest hyperparameters</p> <p>Typical training with 100 paths takes 2-5 minutes including API calls.</p>"},{"location":"usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/#api-key-not-found","title":"API Key Not Found","text":"<p>If you get an API key error, verify the file path and permissions:</p> <pre><code>cat /path/to/openai.key\nchmod 600 /path/to/openai.key\n</code></pre>"},{"location":"usage/#missing-data-file","title":"Missing Data File","text":"<p>Ensure the data file exists and is valid YAML:</p> <pre><code>ls -la data/drugmechdb.yaml\npython -c \"import yaml; yaml.safe_load(open('data/drugmechdb.yaml'))\"\n</code></pre>"},{"location":"usage/#test-failures","title":"Test Failures","text":"<p>Check that all dependencies are installed:</p> <pre><code>uv sync --group dev\n</code></pre> <p>Run tests with verbose output:</p> <pre><code>uv run pytest tests/ -vv -s\n</code></pre>"},{"location":"usage/#next-steps","title":"Next Steps","text":"<ul> <li>Experiment with different classifier hyperparameters</li> <li>Try alternative embeddings or classifiers</li> <li>Load data from KGX format (future implementation)</li> <li>Evaluate on larger datasets</li> <li>Deploy model for production use</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/","title":"Path Embedding Classifier Design","text":"<p>Date: 2025-11-10 Status: Design Complete, Ready for Implementation</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#overview","title":"Overview","text":"<p>Build a binary classifier that distinguishes biologically plausible from implausible mechanistic paths between drugs and diseases using embedding-based representations.</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#core-approach","title":"Core Approach","text":"<ol> <li>Convert mechanistic paths to structured text representations</li> <li>Generate embeddings using OpenAI's embedding API</li> <li>Train a Random Forest classifier on the embeddings</li> <li>Evaluate on held-out test data</li> </ol>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#data-source-drugmechdb","title":"Data Source: DrugMechDB","text":"<p>DrugMechDB provides curated, biologically plausible drug-disease mechanistic paths in YAML format.</p> <p>Data Structure: - Each entry (identified by <code>_id</code>) is a multigraph containing:   - Nodes with <code>id</code>, <code>label</code> (type like Drug, Gene, Protein, Disease), and <code>name</code>   - Edges (links) with <code>key</code> (relationship type), <code>source</code>, and <code>target</code> - Source: https://raw.githubusercontent.com/SuLab/DrugMechDB/refs/heads/main/indication_paths.yaml</p> <p>Path Extraction Strategy: 1. Load each DrugMechDB multigraph using NetworkX 2. Extract all simple paths from drug node to disease node using <code>nx.all_simple_paths()</code> 3. Critical Design Decision: Each extracted path = one separate training example (labeled as plausible) 4. If an indication yields &gt;10 paths, randomly sample 10 to prevent dataset imbalance 5. This creates our positive training examples</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#negative-example-generation","title":"Negative Example Generation","text":"<p>Strategy: Cross-disease shuffling with type matching</p> <p>For each positive path, create a negative example by: 1. Keep the same drug (start) and disease (end) nodes 2. For each intermediate position, maintain the node type (e.g., Gene, Protein, Pathway) 3. Substitute a random node of that type from a different disease context 4. This creates challenging negatives that preserve structural patterns but break biological plausibility</p> <p>Rationale: Simple random shuffling could accidentally create plausible paths. Cross-disease shuffling reduces this risk while creating realistic-looking but implausible examples.</p> <p>Alternative Strategies (noted for future exploration): - Random walks through combined node/edge pool - Stratified random sampling - Combination of multiple strategies</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#text-representation","title":"Text Representation","text":"<p>Format: Structured template with clear delimiters</p> <p>Example:</p> <pre><code>Drug: aspirin | decreases activity of | Protein: COX2 | causes | Disease: inflammation\n</code></pre> <p>Specification: - Alternate between nodes and edges when traversing the path - Nodes: <code>{label}: {name}</code> (e.g., \"Protein: BCR/ABL\") - Edges: relationship type from the <code>key</code> field - Delimiter: <code>|</code> (space-pipe-space) between elements - When multiple edges exist between the same node pair (multigraph), use bundle notation: <code>[edge1|edge2]</code></p> <p>Rationale: - Clear separation between path elements for the embedding model - Node type context alongside names - Readable and machine-parseable - Preserves all mechanistic information</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#future-enhancement-node-context-enrichment","title":"Future Enhancement: Node Context Enrichment","text":"<p>Not implemented initially - start simple, add if needed: - Include one-hop neighbors (subclass-of, part-of relationships) for additional context - Would require external ontology lookups (MESH, DrugBank, UniProt, etc.) - Important note: Previous experiments showed significant improvement for diagnostic use cases when including one-hop neighbors - Plan to add this in a future iteration if basic approach works</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#embedding-generation","title":"Embedding Generation","text":"<ul> <li>Model: OpenAI's text embedding API (text-embedding-3-small or similar)</li> <li>API Key: Load from <code>/Users/jtr4v/openai.key.another</code></li> <li>Process: Each path text \u2192 single fixed-size embedding vector</li> <li>Length handling: No concerns initially - biological mechanism paths are typically short enough for token limits</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#classifier-training","title":"Classifier Training","text":"<p>Classifier: Random Forest (scikit-learn) - Start with default hyperparameters for simplicity - Future consideration: XGBoost if performance needs improvement</p> <p>Train/Test Split: - 80/20 split at the drug-disease indication level - Group all paths belonging to the same drug-disease pair together - Split at the indication level (not individual path level) to prevent data leakage - Ensures the model learns general mechanistic patterns rather than memorizing specific drug-disease combinations - Use fixed random seed for reproducibility</p> <p>Class Balance: - 1:1 ratio of positive to negative examples - For every plausible path, generate one implausible path - Both train and test sets maintain this balance</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#evaluation","title":"Evaluation","text":"<p>Metrics (standard binary classification): - Accuracy - Precision - Recall - F1-score - ROC-AUC</p> <p>Report all metrics on the held-out 20% test set.</p> <p>Output: - Trained model serialized to disk (pickle or joblib) - Classification report and confusion matrix - Performance metrics summary</p>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#future-extensions","title":"Future Extensions","text":""},{"location":"plans/2025-11-10-path-embedding-classifier-design/#kgx-format-support","title":"KGX Format Support","text":"<ul> <li>Create stub/placeholder for KGX path ingestion</li> <li>KGX (Knowledge Graph Exchange) is a JSON/TSV format for knowledge graphs</li> <li>Will need adapter to convert KGX nodes/edges to the same internal path representation</li> <li>Not implemented initially - DrugMechDB first, validate approach works</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#alternative-classifiers","title":"Alternative Classifiers","text":"<ul> <li>XGBoost</li> <li>Neural network approaches</li> <li>Ensemble methods</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#project-structure","title":"Project Structure","text":"<pre><code>path-embedding/\n\u251c\u2500\u2500 src/path_embedding/\n\u2502   \u251c\u2500\u2500 cli.py                    # Typer CLI interface\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 drugmechdb.py        # DrugMechDB loading and path extraction\n\u2502   \u2502   \u251c\u2500\u2500 kgx.py               # KGX stub (future)\n\u2502   \u2502   \u2514\u2500\u2500 negative_sampling.py # Cross-disease shuffling logic\n\u2502   \u251c\u2500\u2500 embedding/\n\u2502   \u2502   \u251c\u2500\u2500 text_formatter.py    # Path \u2192 structured text conversion\n\u2502   \u2502   \u2514\u2500\u2500 openai_embedder.py   # OpenAI API integration\n\u2502   \u251c\u2500\u2500 model/\n\u2502   \u2502   \u251c\u2500\u2500 classifier.py        # Random Forest training/evaluation\n\u2502   \u2502   \u2514\u2500\u2500 evaluation.py        # Metrics and reporting\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u2514\u2500\u2500 path_extraction.py   # NetworkX path extraction utilities\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_path_extraction.py\n\u2502   \u251c\u2500\u2500 test_text_formatter.py\n\u2502   \u251c\u2500\u2500 test_negative_sampling.py\n\u2502   \u2514\u2500\u2500 test_integration.py\n\u251c\u2500\u2500 data/                         # Downloaded DrugMechDB YAML\n\u2514\u2500\u2500 models/                       # Saved trained models\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#cli-interface-proposed","title":"CLI Interface (Proposed)","text":"<pre><code># Train classifier on DrugMechDB\nuv run path-embedding train --data data/indication_paths.yaml --output models/classifier.pkl\n\n# Evaluate on test set\nuv run path-embedding evaluate --model models/classifier.pkl --test-data data/test.pkl\n\n# Predict plausibility of paths from KGX (future)\nuv run path-embedding predict --model models/classifier.pkl --input paths.kgx.json\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#key-design-decisions-summary","title":"Key Design Decisions Summary","text":"<ol> <li>Each path = separate example: Extract all simple paths from multigraphs, treat each as independent training example</li> <li>Cross-disease shuffling: Generate negatives by swapping nodes across disease contexts while preserving types</li> <li>Structured text format: Use template with delimiters for clear, parseable path representation</li> <li>Indication-level split: Split train/test at drug-disease pair level to prevent leakage</li> <li>Start simple: Random Forest, basic text representation, add complexity incrementally</li> <li>OpenAI embeddings: Use commercial API for high-quality embeddings</li> <li>DrugMechDB first: Validate approach before adding KGX support</li> </ol>"},{"location":"plans/2025-11-10-path-embedding-classifier-design/#implementation-priority","title":"Implementation Priority","text":"<ol> <li>DrugMechDB data loading and path extraction (NetworkX)</li> <li>Text formatting and OpenAI embedding generation</li> <li>Negative example generation (cross-disease shuffling)</li> <li>Train/test splitting (indication-level)</li> <li>Random Forest training and evaluation</li> <li>CLI interface for training and evaluation</li> <li>KGX stub (minimal, for future work)</li> </ol>"},{"location":"plans/2025-11-10-path-embedding-implementation/","title":"Path Embedding Classifier Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Build a binary classifier that distinguishes biologically plausible from implausible drug-disease mechanistic paths using LLM embeddings.</p> <p>Architecture: Extract paths from DrugMechDB multigraphs, convert to structured text, embed with OpenAI API, train Random Forest classifier. Generate negative examples via cross-disease shuffling with type matching. Split train/test at indication level to prevent leakage.</p> <p>Tech Stack: NetworkX (multigraphs), OpenAI embeddings API, scikit-learn (Random Forest), pytest (TDD), typer (CLI)</p> <p>Design Document: 2025-11-10-path-embedding-classifier-design.md</p>"},{"location":"plans/2025-11-10-path-embedding-implementation/#prerequisites","title":"Prerequisites","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-0-add-dependencies","title":"Task 0: Add Dependencies","text":"<p>Step 1: Add required dependencies</p> <p>Run:</p> <pre><code>uv add networkx openai numpy scikit-learn pyyaml requests\n</code></pre> <p>Expected: Dependencies added to pyproject.toml and installed</p> <p>Step 2: Verify installation</p> <p>Run:</p> <pre><code>uv run python -c \"import networkx, openai, numpy, sklearn, yaml, requests; print('All deps OK')\"\n</code></pre> <p>Expected: \"All deps OK\" printed</p> <p>Step 3: Commit</p> <pre><code>git add pyproject.toml uv.lock\ngit commit -m \"deps: add networkx, openai, sklearn, pyyaml, requests\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-1-data-models-and-path-extraction","title":"Phase 1: Data Models and Path Extraction","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-11-define-core-data-models","title":"Task 1.1: Define Core Data Models","text":"<p>Files: - Create: <code>src/path_embedding/datamodel/types.py</code> - Test: <code>tests/test_types.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_types.py</code>:</p> <pre><code>\"\"\"Tests for core data types.\"\"\"\nfrom path_embedding.datamodel.types import Node, Edge, Path\n\n\ndef test_node_creation():\n    \"\"\"Test creating a Node.\n\n    &gt;&gt;&gt; node = Node(id=\"MESH:D001241\", label=\"Drug\", name=\"aspirin\")\n    &gt;&gt;&gt; node.id\n    'MESH:D001241'\n    &gt;&gt;&gt; node.label\n    'Drug'\n    &gt;&gt;&gt; node.name\n    'aspirin'\n    \"\"\"\n    node = Node(id=\"MESH:D001241\", label=\"Drug\", name=\"aspirin\")\n    assert node.id == \"MESH:D001241\"\n    assert node.label == \"Drug\"\n    assert node.name == \"aspirin\"\n\n\ndef test_edge_creation():\n    \"\"\"Test creating an Edge.\n\n    &gt;&gt;&gt; edge = Edge(key=\"decreases activity of\", source=\"MESH:D001241\", target=\"UniProt:P00519\")\n    &gt;&gt;&gt; edge.key\n    'decreases activity of'\n    \"\"\"\n    edge = Edge(\n        key=\"decreases activity of\",\n        source=\"MESH:D001241\",\n        target=\"UniProt:P00519\"\n    )\n    assert edge.key == \"decreases activity of\"\n    assert edge.source == \"MESH:D001241\"\n    assert edge.target == \"UniProt:P00519\"\n\n\ndef test_path_creation():\n    \"\"\"Test creating a Path.\"\"\"\n    nodes = [\n        Node(id=\"MESH:D001241\", label=\"Drug\", name=\"aspirin\"),\n        Node(id=\"UniProt:P00519\", label=\"Protein\", name=\"COX2\"),\n        Node(id=\"MESH:D010146\", label=\"Disease\", name=\"pain\"),\n    ]\n    edges = [\n        Edge(key=\"inhibits\", source=\"MESH:D001241\", target=\"UniProt:P00519\"),\n        Edge(key=\"causes\", source=\"UniProt:P00519\", target=\"MESH:D010146\"),\n    ]\n    path = Path(\n        nodes=nodes,\n        edges=edges,\n        drug_id=\"MESH:D001241\",\n        disease_id=\"MESH:D010146\",\n        indication_id=\"test_indication_1\"\n    )\n    assert len(path.nodes) == 3\n    assert len(path.edges) == 2\n    assert path.drug_id == \"MESH:D001241\"\n    assert path.disease_id == \"MESH:D010146\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_types.py -v</code></p> <p>Expected: FAIL with \"ModuleNotFoundError: No module named 'path_embedding.datamodel'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create directory: <code>mkdir -p src/path_embedding/datamodel</code></p> <p>Create file <code>src/path_embedding/datamodel/__init__.py</code>:</p> <pre><code>\"\"\"Data models for path embedding.\"\"\"\n</code></pre> <p>Create file <code>src/path_embedding/datamodel/types.py</code>:</p> <pre><code>\"\"\"Core data types for path representation.\"\"\"\nfrom dataclasses import dataclass\nfrom typing import List\n\n\n@dataclass\nclass Node:\n    \"\"\"A node in a mechanistic path.\n\n    Attributes:\n        id: Unique identifier (e.g., MESH:D001241)\n        label: Node type (e.g., Drug, Protein, Disease)\n        name: Human-readable name (e.g., aspirin)\n    \"\"\"\n    id: str\n    label: str\n    name: str\n\n\n@dataclass\nclass Edge:\n    \"\"\"An edge in a mechanistic path.\n\n    Attributes:\n        key: Relationship type (e.g., \"decreases activity of\")\n        source: Source node ID\n        target: Target node ID\n    \"\"\"\n    key: str\n    source: str\n    target: str\n\n\n@dataclass\nclass Path:\n    \"\"\"A complete mechanistic path from drug to disease.\n\n    Attributes:\n        nodes: Ordered list of nodes in the path\n        edges: Ordered list of edges in the path\n        drug_id: ID of the drug (start) node\n        disease_id: ID of the disease (end) node\n        indication_id: Original DrugMechDB indication ID\n    \"\"\"\n    nodes: List[Node]\n    edges: List[Edge]\n    drug_id: str\n    disease_id: str\n    indication_id: str\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_types.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_types.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/datamodel/ tests/test_types.py\ngit commit -m \"feat: add core data models (Node, Edge, Path)\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-12-drugmechdb-data-loader","title":"Task 1.2: DrugMechDB Data Loader","text":"<p>Files: - Create: <code>src/path_embedding/data/__init__.py</code> - Create: <code>src/path_embedding/data/drugmechdb.py</code> - Test: <code>tests/test_drugmechdb.py</code> - Create: <code>tests/data/sample_drugmechdb.yaml</code> (fixture)</p> <p>Step 1: Create test fixture</p> <p>Create file <code>tests/data/sample_drugmechdb.yaml</code>:</p> <pre><code>- _id: DB00619_MESH_D015464_1\n  directed: true\n  graph:\n    disease: Leukemia, Myelogenous, Chronic, BCR-ABL Positive\n    disease_mesh: MESH:D015464\n    drug: imatinib\n    drug_mesh: MESH:D000068877\n    drugbank: DB00619\n  links:\n  - key: decreases activity of\n    source: MESH:D000068877\n    target: UniProt:P00519\n  - key: causes\n    source: UniProt:P00519\n    target: MESH:D015464\n  multigraph: true\n  nodes:\n  - id: MESH:D000068877\n    label: Drug\n    name: imatinib\n  - id: UniProt:P00519\n    label: Protein\n    name: BCR/ABL\n  - id: MESH:D015464\n    label: Disease\n    name: CML (ph+)\n- _id: DB00316_MESH_D010146_1\n  directed: true\n  graph:\n    disease: Pain\n    disease_mesh: MESH:D010146\n    drug: Acetaminophen\n    drug_mesh: MESH:D000082\n    drugbank: DB00316\n  links:\n  - key: decreases activity of\n    source: MESH:D000082\n    target: UniProt:P23219\n  - key: positively regulates\n    source: UniProt:P23219\n    target: GO:0001516\n  - key: positively regulates\n    source: GO:0001516\n    target: MESH:D015232\n  - key: positively correlated with\n    source: MESH:D015232\n    target: MESH:D010146\n  multigraph: true\n  nodes:\n  - id: MESH:D000082\n    label: Drug\n    name: Acetaminophen\n  - id: UniProt:P23219\n    label: Protein\n    name: PTGS2\n  - id: GO:0001516\n    label: BiologicalProcess\n    name: prostaglandin biosynthetic process\n  - id: MESH:D015232\n    label: ChemicalSubstance\n    name: Dinoprostone\n  - id: MESH:D010146\n    label: Disease\n    name: Pain\n</code></pre> <p>Step 2: Write the failing test</p> <p>Create file <code>tests/test_drugmechdb.py</code>:</p> <pre><code>\"\"\"Tests for DrugMechDB data loading.\"\"\"\nfrom pathlib import Path\nfrom path_embedding.data.drugmechdb import load_drugmechdb\n\n\ndef test_load_drugmechdb():\n    \"\"\"Test loading DrugMechDB YAML file.\n\n    &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    &gt;&gt;&gt; len(indications)\n    2\n    &gt;&gt;&gt; indications[0][\"_id\"]\n    'DB00619_MESH_D015464_1'\n    \"\"\"\n    test_file = \"tests/data/sample_drugmechdb.yaml\"\n    indications = load_drugmechdb(test_file)\n\n    assert len(indications) == 2\n    assert indications[0][\"_id\"] == \"DB00619_MESH_D015464_1\"\n    assert indications[1][\"_id\"] == \"DB00316_MESH_D010146_1\"\n\n\ndef test_load_drugmechdb_structure():\n    \"\"\"Test that loaded data has correct structure.\"\"\"\n    test_file = \"tests/data/sample_drugmechdb.yaml\"\n    indications = load_drugmechdb(test_file)\n\n    indication = indications[0]\n    assert \"nodes\" in indication\n    assert \"links\" in indication\n    assert \"graph\" in indication\n    assert indication[\"directed\"] is True\n    assert indication[\"multigraph\"] is True\n\n\ndef test_load_drugmechdb_nodes():\n    \"\"\"Test node structure.\"\"\"\n    test_file = \"tests/data/sample_drugmechdb.yaml\"\n    indications = load_drugmechdb(test_file)\n\n    nodes = indications[0][\"nodes\"]\n    assert len(nodes) == 3\n\n    drug_node = nodes[0]\n    assert drug_node[\"id\"] == \"MESH:D000068877\"\n    assert drug_node[\"label\"] == \"Drug\"\n    assert drug_node[\"name\"] == \"imatinib\"\n\n\ndef test_load_drugmechdb_edges():\n    \"\"\"Test edge structure.\"\"\"\n    test_file = \"tests/data/sample_drugmechdb.yaml\"\n    indications = load_drugmechdb(test_file)\n\n    links = indications[0][\"links\"]\n    assert len(links) == 2\n\n    edge = links[0]\n    assert edge[\"key\"] == \"decreases activity of\"\n    assert edge[\"source\"] == \"MESH:D000068877\"\n    assert edge[\"target\"] == \"UniProt:P00519\"\n</code></pre> <p>Step 3: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_drugmechdb.py -v</code></p> <p>Expected: FAIL with \"ModuleNotFoundError: No module named 'path_embedding.data'\"</p> <p>Step 4: Write minimal implementation</p> <p>Create directory: <code>mkdir -p src/path_embedding/data</code></p> <p>Create file <code>src/path_embedding/data/__init__.py</code>:</p> <pre><code>\"\"\"Data loading and processing modules.\"\"\"\n</code></pre> <p>Create file <code>src/path_embedding/data/drugmechdb.py</code>:</p> <pre><code>\"\"\"DrugMechDB data loading utilities.\"\"\"\nfrom typing import List, Dict, Any\nimport yaml\n\n\ndef load_drugmechdb(file_path: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"Load DrugMechDB YAML file.\n\n    Args:\n        file_path: Path to DrugMechDB YAML file\n\n    Returns:\n        List of indication entries (multigraphs)\n\n    Example:\n        &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n        &gt;&gt;&gt; len(indications) &gt;= 1\n        True\n        &gt;&gt;&gt; \"nodes\" in indications[0]\n        True\n    \"\"\"\n    with open(file_path, 'r') as f:\n        indications = yaml.safe_load(f)\n\n    return indications\n</code></pre> <p>Step 5: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_drugmechdb.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 6: Run doctests</p> <p>Run: <code>uv run pytest tests/test_drugmechdb.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 7: Commit</p> <pre><code>git add src/path_embedding/data/ tests/test_drugmechdb.py tests/data/\ngit commit -m \"feat: add DrugMechDB YAML loader\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-13-networkx-multigraph-construction","title":"Task 1.3: NetworkX Multigraph Construction","text":"<p>Files: - Create: <code>src/path_embedding/utils/__init__.py</code> - Create: <code>src/path_embedding/utils/path_extraction.py</code> - Test: <code>tests/test_path_extraction.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_path_extraction.py</code>:</p> <pre><code>\"\"\"Tests for path extraction from multigraphs.\"\"\"\nimport networkx as nx\nfrom path_embedding.utils.path_extraction import build_multigraph, find_drug_disease_nodes\nfrom path_embedding.data.drugmechdb import load_drugmechdb\n\n\ndef test_build_multigraph():\n    \"\"\"Test building NetworkX multigraph from indication.\n\n    &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    &gt;&gt;&gt; graph = build_multigraph(indications[0])\n    &gt;&gt;&gt; isinstance(graph, nx.MultiDiGraph)\n    True\n    &gt;&gt;&gt; graph.number_of_nodes()\n    3\n    &gt;&gt;&gt; graph.number_of_edges()\n    2\n    \"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    indication = indications[0]\n\n    graph = build_multigraph(indication)\n\n    assert isinstance(graph, nx.MultiDiGraph)\n    assert graph.number_of_nodes() == 3\n    assert graph.number_of_edges() == 2\n\n\ndef test_build_multigraph_node_attributes():\n    \"\"\"Test that nodes have correct attributes.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[0])\n\n    # Check drug node\n    drug_id = \"MESH:D000068877\"\n    assert drug_id in graph.nodes\n    assert graph.nodes[drug_id][\"label\"] == \"Drug\"\n    assert graph.nodes[drug_id][\"name\"] == \"imatinib\"\n\n\ndef test_build_multigraph_edge_attributes():\n    \"\"\"Test that edges have correct attributes.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[0])\n\n    # Check edge\n    edges = list(graph.edges(data=True, keys=True))\n    source, target, key, data = edges[0]\n\n    assert data[\"key\"] == \"decreases activity of\"\n\n\ndef test_find_drug_disease_nodes():\n    \"\"\"Test finding drug and disease nodes in graph.\n\n    &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    &gt;&gt;&gt; graph = build_multigraph(indications[0])\n    &gt;&gt;&gt; drug_id, disease_id = find_drug_disease_nodes(graph)\n    &gt;&gt;&gt; drug_id\n    'MESH:D000068877'\n    &gt;&gt;&gt; disease_id\n    'MESH:D015464'\n    \"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[0])\n\n    drug_id, disease_id = find_drug_disease_nodes(graph)\n\n    assert drug_id == \"MESH:D000068877\"\n    assert disease_id == \"MESH:D015464\"\n    assert graph.nodes[drug_id][\"label\"] == \"Drug\"\n    assert graph.nodes[disease_id][\"label\"] == \"Disease\"\n\n\ndef test_find_drug_disease_nodes_second_example():\n    \"\"\"Test with second example (multiple intermediate nodes).\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[1])\n\n    drug_id, disease_id = find_drug_disease_nodes(graph)\n\n    assert graph.nodes[drug_id][\"label\"] == \"Drug\"\n    assert graph.nodes[disease_id][\"label\"] == \"Disease\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py -v</code></p> <p>Expected: FAIL with \"ModuleNotFoundError: No module named 'path_embedding.utils'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create directory: <code>mkdir -p src/path_embedding/utils</code></p> <p>Create file <code>src/path_embedding/utils/__init__.py</code>:</p> <pre><code>\"\"\"Utility modules.\"\"\"\n</code></pre> <p>Create file <code>src/path_embedding/utils/path_extraction.py</code>:</p> <pre><code>\"\"\"Path extraction from NetworkX multigraphs.\"\"\"\nfrom typing import Dict, Any, Tuple\nimport networkx as nx\n\n\ndef build_multigraph(indication: Dict[str, Any]) -&gt; nx.MultiDiGraph:\n    \"\"\"Build NetworkX MultiDiGraph from DrugMechDB indication.\n\n    Args:\n        indication: DrugMechDB indication entry with nodes and links\n\n    Returns:\n        NetworkX MultiDiGraph with nodes and edges\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.data.drugmechdb import load_drugmechdb\n        &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n        &gt;&gt;&gt; graph = build_multigraph(indications[0])\n        &gt;&gt;&gt; graph.number_of_nodes() &gt;= 3\n        True\n    \"\"\"\n    graph = nx.MultiDiGraph()\n\n    # Add nodes with attributes\n    for node in indication[\"nodes\"]:\n        graph.add_node(\n            node[\"id\"],\n            label=node[\"label\"],\n            name=node[\"name\"]\n        )\n\n    # Add edges with attributes\n    for link in indication[\"links\"]:\n        graph.add_edge(\n            link[\"source\"],\n            link[\"target\"],\n            key=link[\"key\"]\n        )\n\n    return graph\n\n\ndef find_drug_disease_nodes(graph: nx.MultiDiGraph) -&gt; Tuple[str, str]:\n    \"\"\"Find drug and disease node IDs in graph.\n\n    Args:\n        graph: NetworkX MultiDiGraph with labeled nodes\n\n    Returns:\n        Tuple of (drug_id, disease_id)\n\n    Raises:\n        ValueError: If drug or disease node not found\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.data.drugmechdb import load_drugmechdb\n        &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n        &gt;&gt;&gt; graph = build_multigraph(indications[0])\n        &gt;&gt;&gt; drug_id, disease_id = find_drug_disease_nodes(graph)\n        &gt;&gt;&gt; isinstance(drug_id, str) and isinstance(disease_id, str)\n        True\n    \"\"\"\n    drug_id = None\n    disease_id = None\n\n    for node_id, attrs in graph.nodes(data=True):\n        if attrs[\"label\"] == \"Drug\":\n            drug_id = node_id\n        elif attrs[\"label\"] == \"Disease\":\n            disease_id = node_id\n\n    if drug_id is None:\n        raise ValueError(\"No Drug node found in graph\")\n    if disease_id is None:\n        raise ValueError(\"No Disease node found in graph\")\n\n    return drug_id, disease_id\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/utils/ tests/test_path_extraction.py\ngit commit -m \"feat: add NetworkX multigraph construction\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-14-extract-paths-from-multigraph","title":"Task 1.4: Extract Paths from Multigraph","text":"<p>Files: - Modify: <code>src/path_embedding/utils/path_extraction.py</code> - Modify: <code>tests/test_path_extraction.py</code></p> <p>Step 1: Write the failing test</p> <p>Add to <code>tests/test_path_extraction.py</code>:</p> <pre><code>from path_embedding.utils.path_extraction import extract_paths\nfrom path_embedding.datamodel.types import Path\n\n\ndef test_extract_paths_simple():\n    \"\"\"Test extracting paths from simple graph.\n\n    &gt;&gt;&gt; from path_embedding.data.drugmechdb import load_drugmechdb\n    &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    &gt;&gt;&gt; graph = build_multigraph(indications[0])\n    &gt;&gt;&gt; paths = extract_paths(graph, \"DB00619_MESH_D015464_1\")\n    &gt;&gt;&gt; len(paths)\n    1\n    &gt;&gt;&gt; isinstance(paths[0], Path)\n    True\n    \"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    indication = indications[0]\n    graph = build_multigraph(indication)\n\n    paths = extract_paths(graph, indication[\"_id\"])\n\n    assert len(paths) == 1\n    assert isinstance(paths[0], Path)\n\n\ndef test_extract_paths_structure():\n    \"\"\"Test that extracted path has correct structure.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    indication = indications[0]\n    graph = build_multigraph(indication)\n\n    paths = extract_paths(graph, indication[\"_id\"])\n    path = paths[0]\n\n    # Should have 3 nodes: Drug -&gt; Protein -&gt; Disease\n    assert len(path.nodes) == 3\n    # Should have 2 edges\n    assert len(path.edges) == 2\n\n    # Check drug and disease\n    assert path.drug_id == \"MESH:D000068877\"\n    assert path.disease_id == \"MESH:D015464\"\n    assert path.indication_id == \"DB00619_MESH_D015464_1\"\n\n    # Check node order\n    assert path.nodes[0].label == \"Drug\"\n    assert path.nodes[1].label == \"Protein\"\n    assert path.nodes[2].label == \"Disease\"\n\n\ndef test_extract_paths_multiple():\n    \"\"\"Test extracting multiple paths.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    indication = indications[1]  # Second example has longer path\n    graph = build_multigraph(indication)\n\n    paths = extract_paths(graph, indication[\"_id\"])\n\n    # Should extract at least one path\n    assert len(paths) &gt;= 1\n\n    # All paths should start with Drug and end with Disease\n    for path in paths:\n        assert path.nodes[0].label == \"Drug\"\n        assert path.nodes[-1].label == \"Disease\"\n\n\ndef test_extract_paths_max_limit():\n    \"\"\"Test limiting number of paths extracted.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    indication = indications[0]\n    graph = build_multigraph(indication)\n\n    # Extract with limit\n    paths = extract_paths(graph, indication[\"_id\"], max_paths=1)\n\n    assert len(paths) &lt;= 1\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py::test_extract_paths_simple -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'extract_paths'\"</p> <p>Step 3: Write minimal implementation</p> <p>Add to <code>src/path_embedding/utils/path_extraction.py</code>:</p> <pre><code>from typing import List\nfrom path_embedding.datamodel.types import Node, Edge, Path\nimport random\n\n\ndef extract_paths(\n    graph: nx.MultiDiGraph,\n    indication_id: str,\n    max_paths: int = 10\n) -&gt; List[Path]:\n    \"\"\"Extract all simple paths from drug to disease in multigraph.\n\n    Args:\n        graph: NetworkX MultiDiGraph\n        indication_id: Original DrugMechDB indication ID\n        max_paths: Maximum number of paths to extract (randomly sample if more)\n\n    Returns:\n        List of Path objects\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.data.drugmechdb import load_drugmechdb\n        &gt;&gt;&gt; indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n        &gt;&gt;&gt; graph = build_multigraph(indications[0])\n        &gt;&gt;&gt; paths = extract_paths(graph, indications[0][\"_id\"])\n        &gt;&gt;&gt; len(paths) &gt;= 1\n        True\n    \"\"\"\n    # Find drug and disease nodes\n    drug_id, disease_id = find_drug_disease_nodes(graph)\n\n    # Extract all simple paths\n    all_node_paths = list(nx.all_simple_paths(graph, drug_id, disease_id))\n\n    # Sample if too many paths\n    if len(all_node_paths) &gt; max_paths:\n        all_node_paths = random.sample(all_node_paths, max_paths)\n\n    # Convert to Path objects\n    paths = []\n    for node_path in all_node_paths:\n        # Build nodes list\n        nodes = []\n        for node_id in node_path:\n            node_data = graph.nodes[node_id]\n            nodes.append(Node(\n                id=node_id,\n                label=node_data[\"label\"],\n                name=node_data[\"name\"]\n            ))\n\n        # Build edges list\n        edges = []\n        for i in range(len(node_path) - 1):\n            source = node_path[i]\n            target = node_path[i + 1]\n\n            # Get edge data (handle multigraph - may have multiple edges)\n            edge_data = graph.get_edge_data(source, target)\n            # Take first edge if multiple exist\n            edge_key = list(edge_data.keys())[0]\n            edge_attrs = edge_data[edge_key]\n\n            edges.append(Edge(\n                key=edge_attrs[\"key\"],\n                source=source,\n                target=target\n            ))\n\n        paths.append(Path(\n            nodes=nodes,\n            edges=edges,\n            drug_id=drug_id,\n            disease_id=disease_id,\n            indication_id=indication_id\n        ))\n\n    return paths\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_path_extraction.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/utils/path_extraction.py tests/test_path_extraction.py\ngit commit -m \"feat: add path extraction from multigraphs\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-2-text-formatting","title":"Phase 2: Text Formatting","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-21-path-to-text-conversion","title":"Task 2.1: Path to Text Conversion","text":"<p>Files: - Create: <code>src/path_embedding/embedding/__init__.py</code> - Create: <code>src/path_embedding/embedding/text_formatter.py</code> - Test: <code>tests/test_text_formatter.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_text_formatter.py</code>:</p> <pre><code>\"\"\"Tests for path to text conversion.\"\"\"\nfrom path_embedding.embedding.text_formatter import path_to_text\nfrom path_embedding.datamodel.types import Node, Edge, Path\n\n\ndef test_path_to_text_simple():\n    \"\"\"Test converting simple path to text.\n\n    &gt;&gt;&gt; nodes = [\n    ...     Node(id=\"MESH:D001241\", label=\"Drug\", name=\"aspirin\"),\n    ...     Node(id=\"UniProt:P00519\", label=\"Protein\", name=\"COX2\"),\n    ...     Node(id=\"MESH:D010146\", label=\"Disease\", name=\"pain\")\n    ... ]\n    &gt;&gt;&gt; edges = [\n    ...     Edge(key=\"inhibits\", source=\"MESH:D001241\", target=\"UniProt:P00519\"),\n    ...     Edge(key=\"causes\", source=\"UniProt:P00519\", target=\"MESH:D010146\")\n    ... ]\n    &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"MESH:D001241\",\n    ...             disease_id=\"MESH:D010146\", indication_id=\"test\")\n    &gt;&gt;&gt; text = path_to_text(path)\n    &gt;&gt;&gt; text\n    'Drug: aspirin | inhibits | Protein: COX2 | causes | Disease: pain'\n    \"\"\"\n    nodes = [\n        Node(id=\"MESH:D001241\", label=\"Drug\", name=\"aspirin\"),\n        Node(id=\"UniProt:P00519\", label=\"Protein\", name=\"COX2\"),\n        Node(id=\"MESH:D010146\", label=\"Disease\", name=\"pain\"),\n    ]\n    edges = [\n        Edge(key=\"inhibits\", source=\"MESH:D001241\", target=\"UniProt:P00519\"),\n        Edge(key=\"causes\", source=\"UniProt:P00519\", target=\"MESH:D010146\"),\n    ]\n    path = Path(\n        nodes=nodes,\n        edges=edges,\n        drug_id=\"MESH:D001241\",\n        disease_id=\"MESH:D010146\",\n        indication_id=\"test_1\"\n    )\n\n    text = path_to_text(path)\n\n    expected = \"Drug: aspirin | inhibits | Protein: COX2 | causes | Disease: pain\"\n    assert text == expected\n\n\ndef test_path_to_text_real_example():\n    \"\"\"Test with real DrugMechDB example.\"\"\"\n    from path_embedding.data.drugmechdb import load_drugmechdb\n    from path_embedding.utils.path_extraction import build_multigraph, extract_paths\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[0])\n    paths = extract_paths(graph, indications[0][\"_id\"])\n\n    text = path_to_text(paths[0])\n\n    # Should contain all components\n    assert \"Drug:\" in text\n    assert \"Protein:\" in text\n    assert \"Disease:\" in text\n    assert \"|\" in text\n    assert \"decreases activity of\" in text or \"causes\" in text\n\n\ndef test_path_to_text_format():\n    \"\"\"Test text format structure.\"\"\"\n    nodes = [\n        Node(id=\"A\", label=\"Drug\", name=\"drugA\"),\n        Node(id=\"B\", label=\"Gene\", name=\"geneB\"),\n        Node(id=\"C\", label=\"Disease\", name=\"diseaseC\"),\n    ]\n    edges = [\n        Edge(key=\"regulates\", source=\"A\", target=\"B\"),\n        Edge(key=\"affects\", source=\"B\", target=\"C\"),\n    ]\n    path = Path(\n        nodes=nodes, edges=edges,\n        drug_id=\"A\", disease_id=\"C\", indication_id=\"test\"\n    )\n\n    text = path_to_text(path)\n\n    # Check format: Node | Edge | Node | Edge | Node\n    parts = [p.strip() for p in text.split(\"|\")]\n    assert len(parts) == 5\n    assert parts[0].startswith(\"Drug:\")\n    assert parts[2].startswith(\"Gene:\")\n    assert parts[4].startswith(\"Disease:\")\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_text_formatter.py -v</code></p> <p>Expected: FAIL with \"ModuleNotFoundError: No module named 'path_embedding.embedding'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create directory: <code>mkdir -p src/path_embedding/embedding</code></p> <p>Create file <code>src/path_embedding/embedding/__init__.py</code>:</p> <pre><code>\"\"\"Embedding generation modules.\"\"\"\n</code></pre> <p>Create file <code>src/path_embedding/embedding/text_formatter.py</code>:</p> <pre><code>\"\"\"Convert paths to structured text representations.\"\"\"\nfrom path_embedding.datamodel.types import Path\n\n\ndef path_to_text(path: Path) -&gt; str:\n    \"\"\"Convert a Path object to structured text format.\n\n    Format: {label}: {name} | {edge_key} | {label}: {name} | ...\n\n    Args:\n        path: Path object to convert\n\n    Returns:\n        Structured text representation\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n        &gt;&gt;&gt; nodes = [\n        ...     Node(id=\"A\", label=\"Drug\", name=\"aspirin\"),\n        ...     Node(id=\"B\", label=\"Protein\", name=\"COX2\"),\n        ...     Node(id=\"C\", label=\"Disease\", name=\"pain\")\n        ... ]\n        &gt;&gt;&gt; edges = [\n        ...     Edge(key=\"inhibits\", source=\"A\", target=\"B\"),\n        ...     Edge(key=\"causes\", source=\"B\", target=\"C\")\n        ... ]\n        &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"A\",\n        ...             disease_id=\"C\", indication_id=\"test\")\n        &gt;&gt;&gt; path_to_text(path)\n        'Drug: aspirin | inhibits | Protein: COX2 | causes | Disease: pain'\n    \"\"\"\n    parts = []\n\n    for i, node in enumerate(path.nodes):\n        # Add node\n        parts.append(f\"{node.label}: {node.name}\")\n\n        # Add edge if not last node\n        if i &lt; len(path.edges):\n            parts.append(path.edges[i].key)\n\n    return \" | \".join(parts)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_text_formatter.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_text_formatter.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/embedding/ tests/test_text_formatter.py\ngit commit -m \"feat: add path to text conversion\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-3-negative-sampling","title":"Phase 3: Negative Sampling","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-31-build-node-inventory","title":"Task 3.1: Build Node Inventory","text":"<p>Files: - Create: <code>src/path_embedding/data/negative_sampling.py</code> - Test: <code>tests/test_negative_sampling.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_negative_sampling.py</code>:</p> <pre><code>\"\"\"Tests for negative example generation.\"\"\"\nfrom path_embedding.data.negative_sampling import build_node_inventory\nfrom path_embedding.data.drugmechdb import load_drugmechdb\nfrom path_embedding.utils.path_extraction import build_multigraph, extract_paths\n\n\ndef test_build_node_inventory():\n    \"\"\"Test building node inventory grouped by type and disease.\n\n    &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Path\n    &gt;&gt;&gt; nodes1 = [\n    ...     Node(id=\"D1\", label=\"Drug\", name=\"drug1\"),\n    ...     Node(id=\"G1\", label=\"Gene\", name=\"gene1\"),\n    ...     Node(id=\"DIS1\", label=\"Disease\", name=\"disease1\")\n    ... ]\n    &gt;&gt;&gt; path1 = Path(nodes=nodes1, edges=[], drug_id=\"D1\",\n    ...              disease_id=\"DIS1\", indication_id=\"ind1\")\n    &gt;&gt;&gt; inventory = build_node_inventory([path1])\n    &gt;&gt;&gt; \"Gene\" in inventory\n    True\n    \"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n\n    # Extract all paths\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n\n    # Should have node types as keys\n    assert isinstance(inventory, dict)\n    assert \"Protein\" in inventory or \"BiologicalProcess\" in inventory\n\n    # Each node type should map to disease -&gt; nodes\n    for node_type, disease_dict in inventory.items():\n        assert isinstance(disease_dict, dict)\n\n\ndef test_build_node_inventory_structure():\n    \"\"\"Test inventory structure: {node_type: {disease_id: [nodes]}}.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n\n    # Check structure\n    for node_type, disease_dict in inventory.items():\n        for disease_id, nodes in disease_dict.items():\n            assert isinstance(nodes, list)\n            assert len(nodes) &gt; 0\n            # All nodes should have the expected type\n            for node in nodes:\n                assert node.label == node_type\n\n\ndef test_build_node_inventory_excludes_drug_disease():\n    \"\"\"Test that Drug and Disease nodes are excluded from inventory.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n\n    # Should not include Drug or Disease in inventory\n    assert \"Drug\" not in inventory\n    assert \"Disease\" not in inventory\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py::test_build_node_inventory -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'build_node_inventory'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create file <code>src/path_embedding/data/negative_sampling.py</code>:</p> <pre><code>\"\"\"Generate negative examples via cross-disease shuffling.\"\"\"\nfrom typing import List, Dict\nfrom collections import defaultdict\nfrom path_embedding.datamodel.types import Path, Node\n\n\ndef build_node_inventory(paths: List[Path]) -&gt; Dict[str, Dict[str, List[Node]]]:\n    \"\"\"Build inventory of nodes grouped by type and disease context.\n\n    Structure: {node_type: {disease_id: [nodes]}}\n    Excludes Drug and Disease nodes (only intermediate nodes).\n\n    Args:\n        paths: List of Path objects\n\n    Returns:\n        Nested dict mapping node_type -&gt; disease_id -&gt; list of nodes\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Path\n        &gt;&gt;&gt; nodes = [\n        ...     Node(id=\"D1\", label=\"Drug\", name=\"drug1\"),\n        ...     Node(id=\"G1\", label=\"Gene\", name=\"gene1\"),\n        ...     Node(id=\"DIS1\", label=\"Disease\", name=\"disease1\")\n        ... ]\n        &gt;&gt;&gt; path = Path(nodes=nodes, edges=[], drug_id=\"D1\",\n        ...             disease_id=\"DIS1\", indication_id=\"ind1\")\n        &gt;&gt;&gt; inventory = build_node_inventory([path])\n        &gt;&gt;&gt; \"Gene\" in inventory\n        True\n        &gt;&gt;&gt; \"Drug\" not in inventory\n        True\n    \"\"\"\n    inventory = defaultdict(lambda: defaultdict(list))\n\n    for path in paths:\n        # Get disease context from this path\n        disease_id = path.disease_id\n\n        # Add all intermediate nodes (exclude Drug and Disease)\n        for node in path.nodes:\n            if node.label not in [\"Drug\", \"Disease\"]:\n                # Add to inventory: node_type -&gt; disease_id -&gt; nodes\n                inventory[node.label][disease_id].append(node)\n\n    # Convert to regular dict\n    return {k: dict(v) for k, v in inventory.items()}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/data/negative_sampling.py tests/test_negative_sampling.py\ngit commit -m \"feat: add node inventory builder for negative sampling\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-32-generate-negative-path","title":"Task 3.2: Generate Negative Path","text":"<p>Files: - Modify: <code>src/path_embedding/data/negative_sampling.py</code> - Modify: <code>tests/test_negative_sampling.py</code></p> <p>Step 1: Write the failing test</p> <p>Add to <code>tests/test_negative_sampling.py</code>:</p> <pre><code>from path_embedding.data.negative_sampling import generate_negative_path\nimport random\n\n\ndef test_generate_negative_path():\n    \"\"\"Test generating negative path from positive.\n\n    &gt;&gt;&gt; random.seed(42)\n    &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n    &gt;&gt;&gt; nodes = [\n    ...     Node(id=\"D1\", label=\"Drug\", name=\"drug1\"),\n    ...     Node(id=\"G1\", label=\"Gene\", name=\"gene1\"),\n    ...     Node(id=\"DIS1\", label=\"Disease\", name=\"disease1\")\n    ... ]\n    &gt;&gt;&gt; edges = [\n    ...     Edge(key=\"regulates\", source=\"D1\", target=\"G1\"),\n    ...     Edge(key=\"causes\", source=\"G1\", target=\"DIS1\")\n    ... ]\n    &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"D1\",\n    ...             disease_id=\"DIS1\", indication_id=\"ind1\")\n    &gt;&gt;&gt; inventory = {\"Gene\": {\"DIS2\": [Node(id=\"G2\", label=\"Gene\", name=\"gene2\")]}}\n    &gt;&gt;&gt; neg_path = generate_negative_path(path, inventory)\n    &gt;&gt;&gt; neg_path.nodes[0].id == \"D1\"  # Same drug\n    True\n    &gt;&gt;&gt; neg_path.nodes[-1].id == \"DIS1\"  # Same disease\n    True\n    \"\"\"\n    random.seed(42)\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n    positive_path = all_paths[0]\n\n    negative_path = generate_negative_path(positive_path, inventory)\n\n    # Should preserve drug and disease\n    assert negative_path.drug_id == positive_path.drug_id\n    assert negative_path.disease_id == positive_path.disease_id\n\n    # Should have same number of nodes\n    assert len(negative_path.nodes) == len(positive_path.nodes)\n\n    # First and last nodes should be same\n    assert negative_path.nodes[0].id == positive_path.nodes[0].id\n    assert negative_path.nodes[-1].id == positive_path.nodes[-1].id\n\n\ndef test_generate_negative_path_preserves_types():\n    \"\"\"Test that negative path preserves node types.\"\"\"\n    random.seed(42)\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n\n    # Use second example which has more intermediate nodes\n    positive_path = all_paths[1] if len(all_paths) &gt; 1 else all_paths[0]\n    negative_path = generate_negative_path(positive_path, inventory)\n\n    # Check that node types match in order\n    for i, (pos_node, neg_node) in enumerate(zip(positive_path.nodes, negative_path.nodes)):\n        assert pos_node.label == neg_node.label, f\"Node {i} type mismatch\"\n\n\ndef test_generate_negative_path_different_disease_context():\n    \"\"\"Test that intermediate nodes come from different disease context.\"\"\"\n    random.seed(42)\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n\n    # Need at least 2 different diseases\n    if len(indications) &lt; 2:\n        return  # Skip if not enough data\n\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    inventory = build_node_inventory(all_paths)\n    positive_path = all_paths[0]\n\n    negative_path = generate_negative_path(positive_path, inventory)\n\n    # At least one intermediate node should be different\n    # (if we have enough diversity in the data)\n    intermediate_changed = False\n    for i in range(1, len(positive_path.nodes) - 1):\n        if positive_path.nodes[i].id != negative_path.nodes[i].id:\n            intermediate_changed = True\n            break\n\n    # If we have multiple diseases, should have changed something\n    if len(indications) &gt;= 2:\n        assert intermediate_changed\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py::test_generate_negative_path -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'generate_negative_path'\"</p> <p>Step 3: Write minimal implementation</p> <p>Add to <code>src/path_embedding/data/negative_sampling.py</code>:</p> <pre><code>import random\nfrom path_embedding.datamodel.types import Edge\n\n\ndef generate_negative_path(\n    positive_path: Path,\n    node_inventory: Dict[str, Dict[str, List[Node]]]\n) -&gt; Path:\n    \"\"\"Generate negative path via cross-disease shuffling with type matching.\n\n    Keep drug and disease nodes. For each intermediate node, replace with\n    a random node of the same type from a different disease context.\n\n    Args:\n        positive_path: Original positive Path\n        node_inventory: Inventory from build_node_inventory()\n\n    Returns:\n        Negative Path with shuffled intermediate nodes\n\n    Example:\n        &gt;&gt;&gt; random.seed(42)\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n        &gt;&gt;&gt; nodes = [\n        ...     Node(id=\"D1\", label=\"Drug\", name=\"drug1\"),\n        ...     Node(id=\"G1\", label=\"Gene\", name=\"gene1\"),\n        ...     Node(id=\"DIS1\", label=\"Disease\", name=\"disease1\")\n        ... ]\n        &gt;&gt;&gt; edges = [\n        ...     Edge(key=\"reg\", source=\"D1\", target=\"G1\"),\n        ...     Edge(key=\"causes\", source=\"G1\", target=\"DIS1\")\n        ... ]\n        &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"D1\",\n        ...             disease_id=\"DIS1\", indication_id=\"ind1\")\n        &gt;&gt;&gt; inv = {\"Gene\": {\"DIS2\": [Node(id=\"G2\", label=\"Gene\", name=\"gene2\")]}}\n        &gt;&gt;&gt; neg = generate_negative_path(path, inv)\n        &gt;&gt;&gt; neg.nodes[0].id == \"D1\"  # Same drug\n        True\n    \"\"\"\n    new_nodes = []\n\n    for i, node in enumerate(positive_path.nodes):\n        # Keep drug and disease\n        if node.label in [\"Drug\", \"Disease\"]:\n            new_nodes.append(node)\n        else:\n            # Replace with random node of same type from different disease\n            node_type = node.label\n\n            if node_type in node_inventory:\n                # Get all disease contexts for this node type\n                disease_dict = node_inventory[node_type]\n\n                # Exclude current disease context\n                other_diseases = [\n                    disease_id for disease_id in disease_dict.keys()\n                    if disease_id != positive_path.disease_id\n                ]\n\n                if other_diseases:\n                    # Pick random disease context\n                    random_disease = random.choice(other_diseases)\n                    # Pick random node from that context\n                    random_node = random.choice(disease_dict[random_disease])\n                    new_nodes.append(random_node)\n                else:\n                    # No other disease context, keep original\n                    new_nodes.append(node)\n            else:\n                # Node type not in inventory, keep original\n                new_nodes.append(node)\n\n    # Build new edges with updated source/target IDs\n    new_edges = []\n    for i, edge in enumerate(positive_path.edges):\n        new_edges.append(Edge(\n            key=edge.key,\n            source=new_nodes[i].id,\n            target=new_nodes[i + 1].id\n        ))\n\n    # Create negative path\n    negative_path = Path(\n        nodes=new_nodes,\n        edges=new_edges,\n        drug_id=positive_path.drug_id,\n        disease_id=positive_path.disease_id,\n        indication_id=f\"{positive_path.indication_id}_negative\"\n    )\n\n    return negative_path\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/data/negative_sampling.py tests/test_negative_sampling.py\ngit commit -m \"feat: add negative path generation via cross-disease shuffling\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-33-generate-full-negative-dataset","title":"Task 3.3: Generate Full Negative Dataset","text":"<p>Files: - Modify: <code>src/path_embedding/data/negative_sampling.py</code> - Modify: <code>tests/test_negative_sampling.py</code></p> <p>Step 1: Write the failing test</p> <p>Add to <code>tests/test_negative_sampling.py</code>:</p> <pre><code>from path_embedding.data.negative_sampling import generate_negatives\n\n\ndef test_generate_negatives():\n    \"\"\"Test generating negative dataset.\n\n    &gt;&gt;&gt; random.seed(42)\n    &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n    &gt;&gt;&gt; nodes = [\n    ...     Node(id=\"D1\", label=\"Drug\", name=\"drug1\"),\n    ...     Node(id=\"G1\", label=\"Gene\", name=\"gene1\"),\n    ...     Node(id=\"DIS1\", label=\"Disease\", name=\"disease1\")\n    ... ]\n    &gt;&gt;&gt; edges = [Edge(key=\"reg\", source=\"D1\", target=\"G1\"),\n    ...          Edge(key=\"causes\", source=\"G1\", target=\"DIS1\")]\n    &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"D1\",\n    ...             disease_id=\"DIS1\", indication_id=\"ind1\")\n    &gt;&gt;&gt; negs = generate_negatives([path])\n    &gt;&gt;&gt; len(negs) == 1\n    True\n    \"\"\"\n    random.seed(42)\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    negatives = generate_negatives(all_paths)\n\n    # Should have 1:1 ratio\n    assert len(negatives) == len(all_paths)\n\n    # Each negative should be valid Path\n    for neg in negatives:\n        assert isinstance(neg, Path)\n        assert len(neg.nodes) &gt; 0\n        assert neg.nodes[0].label == \"Drug\"\n        assert neg.nodes[-1].label == \"Disease\"\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py::test_generate_negatives -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'generate_negatives'\"</p> <p>Step 3: Write minimal implementation</p> <p>Add to <code>src/path_embedding/data/negative_sampling.py</code>:</p> <pre><code>def generate_negatives(positive_paths: List[Path]) -&gt; List[Path]:\n    \"\"\"Generate negative examples for all positive paths.\n\n    Creates 1:1 ratio of positives to negatives using cross-disease shuffling.\n\n    Args:\n        positive_paths: List of positive Path objects\n\n    Returns:\n        List of negative Path objects (same length as input)\n\n    Example:\n        &gt;&gt;&gt; random.seed(42)\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n        &gt;&gt;&gt; nodes = [\n        ...     Node(id=\"D1\", label=\"Drug\", name=\"d1\"),\n        ...     Node(id=\"G1\", label=\"Gene\", name=\"g1\"),\n        ...     Node(id=\"DIS1\", label=\"Disease\", name=\"dis1\")\n        ... ]\n        &gt;&gt;&gt; edges = [Edge(key=\"r\", source=\"D1\", target=\"G1\"),\n        ...          Edge(key=\"c\", source=\"G1\", target=\"DIS1\")]\n        &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"D1\",\n        ...             disease_id=\"DIS1\", indication_id=\"i1\")\n        &gt;&gt;&gt; negs = generate_negatives([path])\n        &gt;&gt;&gt; len(negs)\n        1\n    \"\"\"\n    # Build node inventory from all positive paths\n    inventory = build_node_inventory(positive_paths)\n\n    # Generate one negative for each positive\n    negatives = []\n    for positive_path in positive_paths:\n        negative_path = generate_negative_path(positive_path, inventory)\n        negatives.append(negative_path)\n\n    return negatives\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_negative_sampling.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/data/negative_sampling.py tests/test_negative_sampling.py\ngit commit -m \"feat: add full negative dataset generation\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-4-openai-embeddings","title":"Phase 4: OpenAI Embeddings","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-41-openai-api-integration","title":"Task 4.1: OpenAI API Integration","text":"<p>Files: - Create: <code>src/path_embedding/embedding/openai_embedder.py</code> - Test: <code>tests/test_openai_embedder.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_openai_embedder.py</code>:</p> <pre><code>\"\"\"Tests for OpenAI embedding generation.\"\"\"\nimport numpy as np\nfrom path_embedding.embedding.openai_embedder import load_api_key, embed_text\n\n\ndef test_load_api_key():\n    \"\"\"Test loading API key from file.\n\n    &gt;&gt;&gt; key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n    &gt;&gt;&gt; len(key) &gt; 0\n    True\n    &gt;&gt;&gt; key.startswith(\"sk-\")\n    True\n    \"\"\"\n    key_path = \"/Users/jtr4v/openai.key.another\"\n    key = load_api_key(key_path)\n\n    assert isinstance(key, str)\n    assert len(key) &gt; 0\n    # OpenAI keys start with \"sk-\"\n    assert key.startswith(\"sk-\")\n\n\ndef test_embed_text():\n    \"\"\"Test embedding simple text with OpenAI API.\n\n    Note: This test makes real API call and may be slow.\n    \"\"\"\n    key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n    text = \"Drug: aspirin | inhibits | Protein: COX2\"\n\n    embedding = embed_text(text, key)\n\n    assert isinstance(embedding, np.ndarray)\n    assert len(embedding.shape) == 1  # 1D array\n    assert embedding.shape[0] &gt; 0  # Has dimensions\n    # text-embedding-3-small has 1536 dimensions\n    assert embedding.shape[0] == 1536\n\n\ndef test_embed_text_different_inputs():\n    \"\"\"Test that different texts produce different embeddings.\"\"\"\n    key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n\n    text1 = \"Drug: aspirin | inhibits | Protein: COX2\"\n    text2 = \"Drug: imatinib | decreases activity of | Protein: BCR/ABL\"\n\n    emb1 = embed_text(text1, key)\n    emb2 = embed_text(text2, key)\n\n    # Embeddings should be different\n    assert not np.array_equal(emb1, emb2)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py::test_load_api_key -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'load_api_key'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create file <code>src/path_embedding/embedding/openai_embedder.py</code>:</p> <pre><code>\"\"\"OpenAI embedding generation.\"\"\"\nimport numpy as np\nfrom openai import OpenAI\n\n\ndef load_api_key(key_path: str) -&gt; str:\n    \"\"\"Load OpenAI API key from file.\n\n    Args:\n        key_path: Path to file containing API key\n\n    Returns:\n        API key as string\n\n    Example:\n        &gt;&gt;&gt; key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n        &gt;&gt;&gt; len(key) &gt; 0\n        True\n    \"\"\"\n    with open(key_path, 'r') as f:\n        api_key = f.read().strip()\n    return api_key\n\n\ndef embed_text(text: str, api_key: str, model: str = \"text-embedding-3-small\") -&gt; np.ndarray:\n    \"\"\"Generate embedding for text using OpenAI API.\n\n    Args:\n        text: Text to embed\n        api_key: OpenAI API key\n        model: OpenAI embedding model (default: text-embedding-3-small)\n\n    Returns:\n        Embedding vector as numpy array\n\n    Example:\n        &gt;&gt;&gt; key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n        &gt;&gt;&gt; emb = embed_text(\"test text\", key)\n        &gt;&gt;&gt; isinstance(emb, np.ndarray)\n        True\n    \"\"\"\n    client = OpenAI(api_key=api_key)\n\n    response = client.embeddings.create(\n        input=text,\n        model=model\n    )\n\n    embedding = np.array(response.data[0].embedding)\n    return embedding\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py::test_load_api_key -v</code></p> <p>Expected: PASS</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py::test_embed_text -v</code></p> <p>Expected: PASS (makes real API call, may take a few seconds)</p> <p>Step 5: Run all embedding tests</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/embedding/openai_embedder.py tests/test_openai_embedder.py\ngit commit -m \"feat: add OpenAI embedding generation\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-42-batch-path-embedding","title":"Task 4.2: Batch Path Embedding","text":"<p>Files: - Modify: <code>src/path_embedding/embedding/openai_embedder.py</code> - Modify: <code>tests/test_openai_embedder.py</code></p> <p>Step 1: Write the failing test</p> <p>Add to <code>tests/test_openai_embedder.py</code>:</p> <pre><code>from path_embedding.embedding.openai_embedder import embed_paths\nfrom path_embedding.data.drugmechdb import load_drugmechdb\nfrom path_embedding.utils.path_extraction import build_multigraph, extract_paths\n\n\ndef test_embed_paths():\n    \"\"\"Test embedding multiple paths.\n\n    Note: Makes real API calls, may be slow.\n    \"\"\"\n    key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n\n    # Load sample paths\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        indication_paths = extract_paths(graph, indication[\"_id\"], max_paths=1)\n        paths.extend(indication_paths)\n\n    embeddings = embed_paths(paths, key)\n\n    # Should return 2D array: n_paths x embedding_dim\n    assert isinstance(embeddings, np.ndarray)\n    assert len(embeddings.shape) == 2\n    assert embeddings.shape[0] == len(paths)\n    assert embeddings.shape[1] == 1536  # text-embedding-3-small dimension\n\n\ndef test_embed_paths_integration():\n    \"\"\"Integration test with text formatter.\"\"\"\n    key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n    graph = build_multigraph(indications[0])\n    paths = extract_paths(graph, indications[0][\"_id\"])\n\n    embeddings = embed_paths(paths, key)\n\n    assert embeddings.shape[0] == len(paths)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py::test_embed_paths -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'embed_paths'\"</p> <p>Step 3: Write minimal implementation</p> <p>Add to <code>src/path_embedding/embedding/openai_embedder.py</code>:</p> <pre><code>from typing import List\nfrom path_embedding.datamodel.types import Path\nfrom path_embedding.embedding.text_formatter import path_to_text\n\n\ndef embed_paths(\n    paths: List[Path],\n    api_key: str,\n    model: str = \"text-embedding-3-small\"\n) -&gt; np.ndarray:\n    \"\"\"Generate embeddings for multiple paths.\n\n    Args:\n        paths: List of Path objects\n        api_key: OpenAI API key\n        model: OpenAI embedding model\n\n    Returns:\n        2D numpy array of shape (n_paths, embedding_dim)\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n        &gt;&gt;&gt; nodes = [\n        ...     Node(id=\"A\", label=\"Drug\", name=\"aspirin\"),\n        ...     Node(id=\"B\", label=\"Protein\", name=\"COX2\"),\n        ...     Node(id=\"C\", label=\"Disease\", name=\"pain\")\n        ... ]\n        &gt;&gt;&gt; edges = [\n        ...     Edge(key=\"inhibits\", source=\"A\", target=\"B\"),\n        ...     Edge(key=\"causes\", source=\"B\", target=\"C\")\n        ... ]\n        &gt;&gt;&gt; path = Path(nodes=nodes, edges=edges, drug_id=\"A\",\n        ...             disease_id=\"C\", indication_id=\"test\")\n        &gt;&gt;&gt; key = load_api_key(\"/Users/jtr4v/openai.key.another\")\n        &gt;&gt;&gt; embs = embed_paths([path], key)\n        &gt;&gt;&gt; embs.shape[0] == 1\n        True\n    \"\"\"\n    embeddings = []\n\n    for path in paths:\n        # Convert path to text\n        text = path_to_text(path)\n\n        # Generate embedding\n        embedding = embed_text(text, api_key, model)\n        embeddings.append(embedding)\n\n    # Stack into 2D array\n    return np.vstack(embeddings)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py::test_embed_paths -v</code></p> <p>Expected: PASS (makes API calls)</p> <p>Step 5: Run all tests</p> <p>Run: <code>uv run pytest tests/test_openai_embedder.py -v</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/embedding/openai_embedder.py tests/test_openai_embedder.py\ngit commit -m \"feat: add batch path embedding\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-5-traintest-split","title":"Phase 5: Train/Test Split","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-51-indication-level-splitting","title":"Task 5.1: Indication-Level Splitting","text":"<p>Files: - Create: <code>src/path_embedding/model/__init__.py</code> - Create: <code>src/path_embedding/model/data_split.py</code> - Test: <code>tests/test_data_split.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_data_split.py</code>:</p> <pre><code>\"\"\"Tests for train/test splitting.\"\"\"\nfrom path_embedding.model.data_split import split_by_indication\nfrom path_embedding.data.drugmechdb import load_drugmechdb\nfrom path_embedding.utils.path_extraction import build_multigraph, extract_paths\n\n\ndef test_split_by_indication():\n    \"\"\"Test splitting paths by indication.\n\n    &gt;&gt;&gt; from path_embedding.datamodel.types import Node, Edge, Path\n    &gt;&gt;&gt; paths = [\n    ...     Path(nodes=[], edges=[], drug_id=\"D1\", disease_id=\"DIS1\",\n    ...          indication_id=\"ind1\"),\n    ...     Path(nodes=[], edges=[], drug_id=\"D1\", disease_id=\"DIS1\",\n    ...          indication_id=\"ind1\"),\n    ...     Path(nodes=[], edges=[], drug_id=\"D2\", disease_id=\"DIS2\",\n    ...          indication_id=\"ind2\"),\n    ... ]\n    &gt;&gt;&gt; train, test = split_by_indication(paths, test_size=0.5, random_seed=42)\n    &gt;&gt;&gt; len(train) + len(test) == 3\n    True\n    \"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    train_paths, test_paths = split_by_indication(\n        all_paths,\n        test_size=0.2,\n        random_seed=42\n    )\n\n    # Should have train and test\n    assert len(train_paths) &gt; 0\n    assert len(test_paths) &gt; 0\n\n    # Total should equal input\n    assert len(train_paths) + len(test_paths) == len(all_paths)\n\n\ndef test_split_by_indication_no_leakage():\n    \"\"\"Test that same indication doesn't appear in both train and test.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    train_paths, test_paths = split_by_indication(\n        all_paths,\n        test_size=0.5,\n        random_seed=42\n    )\n\n    # Get indication IDs from train and test\n    train_indications = set(p.indication_id for p in train_paths)\n    test_indications = set(p.indication_id for p in test_paths)\n\n    # Should have no overlap\n    assert len(train_indications &amp; test_indications) == 0\n\n\ndef test_split_by_indication_reproducible():\n    \"\"\"Test that split is reproducible with same seed.\"\"\"\n    indications = load_drugmechdb(\"tests/data/sample_drugmechdb.yaml\")\n\n    all_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"])\n        all_paths.extend(paths)\n\n    train1, test1 = split_by_indication(all_paths, test_size=0.5, random_seed=42)\n    train2, test2 = split_by_indication(all_paths, test_size=0.5, random_seed=42)\n\n    # Same seed should give same split\n    assert len(train1) == len(train2)\n    assert len(test1) == len(test2)\n\n    train_ids_1 = [p.indication_id for p in train1]\n    train_ids_2 = [p.indication_id for p in train2]\n    assert train_ids_1 == train_ids_2\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_data_split.py -v</code></p> <p>Expected: FAIL with \"ModuleNotFoundError: No module named 'path_embedding.model'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create directory: <code>mkdir -p src/path_embedding/model</code></p> <p>Create file <code>src/path_embedding/model/__init__.py</code>:</p> <pre><code>\"\"\"Model training and evaluation modules.\"\"\"\n</code></pre> <p>Create file <code>src/path_embedding/model/data_split.py</code>:</p> <pre><code>\"\"\"Train/test splitting by indication.\"\"\"\nfrom typing import List, Tuple\nfrom collections import defaultdict\nimport random\nfrom path_embedding.datamodel.types import Path\n\n\ndef split_by_indication(\n    paths: List[Path],\n    test_size: float = 0.2,\n    random_seed: int = 42\n) -&gt; Tuple[List[Path], List[Path]]:\n    \"\"\"Split paths into train/test by indication (drug-disease pair).\n\n    Groups paths by indication_id, then splits at indication level to\n    prevent data leakage.\n\n    Args:\n        paths: List of Path objects\n        test_size: Fraction for test set (default 0.2)\n        random_seed: Random seed for reproducibility\n\n    Returns:\n        Tuple of (train_paths, test_paths)\n\n    Example:\n        &gt;&gt;&gt; from path_embedding.datamodel.types import Path\n        &gt;&gt;&gt; paths = [\n        ...     Path(nodes=[], edges=[], drug_id=\"D1\", disease_id=\"DIS1\",\n        ...          indication_id=\"ind1\"),\n        ...     Path(nodes=[], edges=[], drug_id=\"D2\", disease_id=\"DIS2\",\n        ...          indication_id=\"ind2\"),\n        ... ]\n        &gt;&gt;&gt; train, test = split_by_indication(paths, test_size=0.5, random_seed=42)\n        &gt;&gt;&gt; len(train) + len(test) == 2\n        True\n    \"\"\"\n    random.seed(random_seed)\n\n    # Group paths by indication_id\n    indication_groups = defaultdict(list)\n    for path in paths:\n        indication_groups[path.indication_id].append(path)\n\n    # Get list of indication IDs\n    indication_ids = list(indication_groups.keys())\n\n    # Shuffle and split indication IDs\n    random.shuffle(indication_ids)\n    split_point = int(len(indication_ids) * (1 - test_size))\n\n    train_indication_ids = indication_ids[:split_point]\n    test_indication_ids = indication_ids[split_point:]\n\n    # Collect paths for train and test\n    train_paths = []\n    for ind_id in train_indication_ids:\n        train_paths.extend(indication_groups[ind_id])\n\n    test_paths = []\n    for ind_id in test_indication_ids:\n        test_paths.extend(indication_groups[ind_id])\n\n    return train_paths, test_paths\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_data_split.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_data_split.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/model/ tests/test_data_split.py\ngit commit -m \"feat: add indication-level train/test split\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-6-classifier-training-and-evaluation","title":"Phase 6: Classifier Training and Evaluation","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-61-random-forest-classifier","title":"Task 6.1: Random Forest Classifier","text":"<p>Files: - Create: <code>src/path_embedding/model/classifier.py</code> - Test: <code>tests/test_classifier.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_classifier.py</code>:</p> <pre><code>\"\"\"Tests for classifier training.\"\"\"\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom path_embedding.model.classifier import train_classifier\n\n\ndef test_train_classifier():\n    \"\"\"Test training Random Forest classifier.\n\n    &gt;&gt;&gt; X = np.random.rand(100, 10)\n    &gt;&gt;&gt; y = np.random.randint(0, 2, 100)\n    &gt;&gt;&gt; model = train_classifier(X, y)\n    &gt;&gt;&gt; isinstance(model, RandomForestClassifier)\n    True\n    \"\"\"\n    # Create synthetic data\n    X_train = np.random.rand(100, 10)\n    y_train = np.random.randint(0, 2, 100)\n\n    model = train_classifier(X_train, y_train)\n\n    assert isinstance(model, RandomForestClassifier)\n\n    # Should be able to make predictions\n    predictions = model.predict(X_train)\n    assert predictions.shape[0] == 100\n\n\ndef test_train_classifier_predictions():\n    \"\"\"Test that trained model can make predictions.\"\"\"\n    X_train = np.random.rand(50, 10)\n    y_train = np.random.randint(0, 2, 50)\n\n    model = train_classifier(X_train, y_train)\n\n    X_test = np.random.rand(10, 10)\n    predictions = model.predict(X_test)\n\n    assert predictions.shape[0] == 10\n    # Predictions should be 0 or 1\n    assert all(p in [0, 1] for p in predictions)\n\n\ndef test_train_classifier_probabilities():\n    \"\"\"Test that model can output probabilities.\"\"\"\n    X_train = np.random.rand(50, 10)\n    y_train = np.random.randint(0, 2, 50)\n\n    model = train_classifier(X_train, y_train)\n\n    X_test = np.random.rand(10, 10)\n    probs = model.predict_proba(X_test)\n\n    assert probs.shape == (10, 2)\n    # Probabilities should sum to 1\n    assert np.allclose(probs.sum(axis=1), 1.0)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_classifier.py -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'train_classifier'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create file <code>src/path_embedding/model/classifier.py</code>:</p> <pre><code>\"\"\"Classifier training and prediction.\"\"\"\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ndef train_classifier(\n    X_train: np.ndarray,\n    y_train: np.ndarray,\n    random_state: int = 42\n) -&gt; RandomForestClassifier:\n    \"\"\"Train Random Forest classifier.\n\n    Args:\n        X_train: Training features (n_samples, n_features)\n        y_train: Training labels (n_samples,)\n        random_state: Random seed for reproducibility\n\n    Returns:\n        Trained RandomForestClassifier\n\n    Example:\n        &gt;&gt;&gt; X = np.random.rand(50, 10)\n        &gt;&gt;&gt; y = np.random.randint(0, 2, 50)\n        &gt;&gt;&gt; model = train_classifier(X, y)\n        &gt;&gt;&gt; isinstance(model, RandomForestClassifier)\n        True\n    \"\"\"\n    model = RandomForestClassifier(random_state=random_state)\n    model.fit(X_train, y_train)\n    return model\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_classifier.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_classifier.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/model/classifier.py tests/test_classifier.py\ngit commit -m \"feat: add Random Forest classifier training\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-62-evaluation-metrics","title":"Task 6.2: Evaluation Metrics","text":"<p>Files: - Create: <code>src/path_embedding/model/evaluation.py</code> - Test: <code>tests/test_evaluation.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_evaluation.py</code>:</p> <pre><code>\"\"\"Tests for model evaluation.\"\"\"\nimport numpy as np\nfrom path_embedding.model.evaluation import evaluate_classifier\nfrom path_embedding.model.classifier import train_classifier\n\n\ndef test_evaluate_classifier():\n    \"\"\"Test evaluating classifier with metrics.\n\n    &gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n    &gt;&gt;&gt; X = np.random.rand(50, 10)\n    &gt;&gt;&gt; y = np.array([0] * 25 + [1] * 25)\n    &gt;&gt;&gt; model = RandomForestClassifier(random_state=42)\n    &gt;&gt;&gt; model.fit(X, y)\n    RandomForestClassifier(random_state=42)\n    &gt;&gt;&gt; metrics = evaluate_classifier(model, X, y)\n    &gt;&gt;&gt; \"accuracy\" in metrics\n    True\n    \"\"\"\n    # Create simple dataset\n    X_train = np.random.rand(100, 10)\n    y_train = np.array([0] * 50 + [1] * 50)\n\n    model = train_classifier(X_train, y_train)\n\n    X_test = np.random.rand(50, 10)\n    y_test = np.array([0] * 25 + [1] * 25)\n\n    metrics = evaluate_classifier(model, X_test, y_test)\n\n    # Should have all expected metrics\n    assert \"accuracy\" in metrics\n    assert \"precision\" in metrics\n    assert \"recall\" in metrics\n    assert \"f1\" in metrics\n    assert \"roc_auc\" in metrics\n\n    # All metrics should be between 0 and 1\n    for metric_name, value in metrics.items():\n        assert 0 &lt;= value &lt;= 1, f\"{metric_name} out of range\"\n\n\ndef test_evaluate_classifier_perfect():\n    \"\"\"Test with perfect predictions.\"\"\"\n    # Create separable data\n    X_train = np.vstack([\n        np.random.rand(50, 10) - 1,  # Class 0\n        np.random.rand(50, 10) + 1,  # Class 1\n    ])\n    y_train = np.array([0] * 50 + [1] * 50)\n\n    model = train_classifier(X_train, y_train)\n\n    # Test on training data (should be nearly perfect)\n    metrics = evaluate_classifier(model, X_train, y_train)\n\n    # Should have high accuracy\n    assert metrics[\"accuracy\"] &gt; 0.8\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_evaluation.py -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'evaluate_classifier'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create file <code>src/path_embedding/model/evaluation.py</code>:</p> <pre><code>\"\"\"Model evaluation utilities.\"\"\"\nfrom typing import Dict\nimport numpy as np\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    classification_report,\n    confusion_matrix\n)\n\n\ndef evaluate_classifier(\n    model,\n    X_test: np.ndarray,\n    y_test: np.ndarray\n) -&gt; Dict[str, float]:\n    \"\"\"Evaluate classifier and return metrics.\n\n    Args:\n        model: Trained classifier with predict() and predict_proba()\n        X_test: Test features\n        y_test: Test labels\n\n    Returns:\n        Dict with accuracy, precision, recall, f1, roc_auc\n\n    Example:\n        &gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n        &gt;&gt;&gt; X = np.random.rand(50, 10)\n        &gt;&gt;&gt; y = np.array([0] * 25 + [1] * 25)\n        &gt;&gt;&gt; model = RandomForestClassifier(random_state=42).fit(X, y)\n        &gt;&gt;&gt; metrics = evaluate_classifier(model, X, y)\n        &gt;&gt;&gt; \"accuracy\" in metrics\n        True\n    \"\"\"\n    # Get predictions\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    # Calculate metrics\n    metrics = {\n        \"accuracy\": accuracy_score(y_test, y_pred),\n        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n        \"roc_auc\": roc_auc_score(y_test, y_proba),\n    }\n\n    return metrics\n\n\ndef print_evaluation_report(\n    model,\n    X_test: np.ndarray,\n    y_test: np.ndarray\n) -&gt; None:\n    \"\"\"Print detailed evaluation report.\n\n    Args:\n        model: Trained classifier\n        X_test: Test features\n        y_test: Test labels\n    \"\"\"\n    y_pred = model.predict(X_test)\n\n    print(\"\\n=== Classification Report ===\")\n    print(classification_report(y_test, y_pred, target_names=[\"Implausible\", \"Plausible\"]))\n\n    print(\"\\n=== Confusion Matrix ===\")\n    cm = confusion_matrix(y_test, y_pred)\n    print(cm)\n\n    print(\"\\n=== Metrics Summary ===\")\n    metrics = evaluate_classifier(model, X_test, y_test)\n    for metric_name, value in metrics.items():\n        print(f\"{metric_name}: {value:.4f}\")\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_evaluation.py -v</code></p> <p>Expected: PASS (all tests)</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_evaluation.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/model/evaluation.py tests/test_evaluation.py\ngit commit -m \"feat: add classifier evaluation metrics\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-7-cli-integration","title":"Phase 7: CLI Integration","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-71-training-command","title":"Task 7.1: Training Command","text":"<p>Files: - Modify: <code>src/path_embedding/cli.py</code> - Test: <code>tests/test_cli.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_cli.py</code>:</p> <pre><code>\"\"\"Tests for CLI commands.\"\"\"\nimport os\nimport tempfile\nfrom typer.testing import CliRunner\nfrom path_embedding.cli import app\n\nrunner = CliRunner()\n\n\ndef test_train_command_help():\n    \"\"\"Test that train command shows help.\"\"\"\n    result = runner.invoke(app, [\"train\", \"--help\"])\n    assert result.exit_code == 0\n    assert \"train\" in result.stdout.lower()\n\n\ndef test_train_command_integration():\n    \"\"\"Integration test for train command.\n\n    Note: This makes real API calls and may be slow/expensive.\n    \"\"\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        model_path = os.path.join(tmpdir, \"test_model.pkl\")\n\n        result = runner.invoke(app, [\n            \"train\",\n            \"--data\", \"tests/data/sample_drugmechdb.yaml\",\n            \"--output\", model_path,\n            \"--test-size\", \"0.5\",\n            \"--max-paths-per-indication\", \"1\",\n            \"--api-key-path\", \"/Users/jtr4v/openai.key.another\"\n        ])\n\n        # Should succeed\n        assert result.exit_code == 0\n\n        # Model file should be created\n        assert os.path.exists(model_path)\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_cli.py::test_train_command_help -v</code></p> <p>Expected: FAIL (train command doesn't exist yet)</p> <p>Step 3: Write minimal implementation</p> <p>Modify <code>src/path_embedding/cli.py</code>:</p> <pre><code>\"\"\"CLI interface for path-embedding.\"\"\"\n\nimport typer\nfrom typing_extensions import Annotated\nfrom pathlib import Path\nimport pickle\nimport numpy as np\n\napp = typer.Typer(help=\"path-embedding: Classifier that uses embeddings to find useful paths between drugs and disease\")\n\n\n@app.command()\ndef train(\n    data: Annotated[str, typer.Option(help=\"Path to DrugMechDB YAML file\")],\n    output: Annotated[str, typer.Option(help=\"Path to save trained model (.pkl)\")],\n    api_key_path: Annotated[str, typer.Option(help=\"Path to OpenAI API key file\")] = \"/Users/jtr4v/openai.key.another\",\n    test_size: Annotated[float, typer.Option(help=\"Fraction for test set\")] = 0.2,\n    max_paths_per_indication: Annotated[int, typer.Option(help=\"Max paths to extract per indication\")] = 10,\n    random_seed: Annotated[int, typer.Option(help=\"Random seed\")] = 42,\n):\n    \"\"\"Train path embedding classifier on DrugMechDB data.\"\"\"\n    from path_embedding.data.drugmechdb import load_drugmechdb\n    from path_embedding.utils.path_extraction import build_multigraph, extract_paths\n    from path_embedding.data.negative_sampling import generate_negatives\n    from path_embedding.model.data_split import split_by_indication\n    from path_embedding.embedding.openai_embedder import load_api_key, embed_paths\n    from path_embedding.model.classifier import train_classifier\n    from path_embedding.model.evaluation import evaluate_classifier, print_evaluation_report\n\n    typer.echo(\"Loading DrugMechDB data...\")\n    indications = load_drugmechdb(data)\n    typer.echo(f\"Loaded {len(indications)} indications\")\n\n    typer.echo(\"Extracting paths from multigraphs...\")\n    all_positive_paths = []\n    for indication in indications:\n        graph = build_multigraph(indication)\n        paths = extract_paths(graph, indication[\"_id\"], max_paths=max_paths_per_indication)\n        all_positive_paths.extend(paths)\n    typer.echo(f\"Extracted {len(all_positive_paths)} positive paths\")\n\n    typer.echo(\"Generating negative examples...\")\n    negative_paths = generate_negatives(all_positive_paths)\n    typer.echo(f\"Generated {len(negative_paths)} negative paths\")\n\n    typer.echo(\"Splitting train/test by indication...\")\n    train_pos, test_pos = split_by_indication(all_positive_paths, test_size=test_size, random_seed=random_seed)\n    train_neg, test_neg = split_by_indication(negative_paths, test_size=test_size, random_seed=random_seed)\n\n    train_paths = train_pos + train_neg\n    test_paths = test_pos + test_neg\n\n    train_labels = np.array([1] * len(train_pos) + [0] * len(train_neg))\n    test_labels = np.array([1] * len(test_pos) + [0] * len(test_neg))\n\n    typer.echo(f\"Train: {len(train_paths)} paths ({len(train_pos)} pos, {len(train_neg)} neg)\")\n    typer.echo(f\"Test: {len(test_paths)} paths ({len(test_pos)} pos, {len(test_neg)} neg)\")\n\n    typer.echo(\"Loading API key...\")\n    api_key = load_api_key(api_key_path)\n\n    typer.echo(\"Generating embeddings for training set...\")\n    train_embeddings = embed_paths(train_paths, api_key)\n    typer.echo(f\"Train embeddings shape: {train_embeddings.shape}\")\n\n    typer.echo(\"Generating embeddings for test set...\")\n    test_embeddings = embed_paths(test_paths, api_key)\n    typer.echo(f\"Test embeddings shape: {test_embeddings.shape}\")\n\n    typer.echo(\"Training Random Forest classifier...\")\n    model = train_classifier(train_embeddings, train_labels, random_state=random_seed)\n\n    typer.echo(\"Evaluating on test set...\")\n    print_evaluation_report(model, test_embeddings, test_labels)\n\n    typer.echo(f\"Saving model to {output}...\")\n    with open(output, 'wb') as f:\n        pickle.dump(model, f)\n\n    typer.echo(\"Training complete!\")\n\n\ndef main():\n    \"\"\"Main entry point for the CLI.\"\"\"\n    app()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_cli.py::test_train_command_help -v</code></p> <p>Expected: PASS</p> <p>Run full integration test (this will make API calls): <code>uv run pytest tests/test_cli.py::test_train_command_integration -v</code></p> <p>Expected: PASS (may take time due to API calls)</p> <p>Step 5: Test manually</p> <p>Run: <code>uv run path-embedding train --help</code></p> <p>Expected: Shows help for train command</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/cli.py tests/test_cli.py\ngit commit -m \"feat: add train CLI command\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#phase-8-kgx-stub","title":"Phase 8: KGX Stub","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-81-kgx-loader-stub","title":"Task 8.1: KGX Loader Stub","text":"<p>Files: - Create: <code>src/path_embedding/data/kgx.py</code> - Test: <code>tests/test_kgx.py</code></p> <p>Step 1: Write the failing test</p> <p>Create file <code>tests/test_kgx.py</code>:</p> <pre><code>\"\"\"Tests for KGX data loading (stub).\"\"\"\nimport pytest\nfrom path_embedding.data.kgx import load_kgx_paths\n\n\ndef test_load_kgx_paths_not_implemented():\n    \"\"\"Test that KGX loader raises NotImplementedError.\n\n    &gt;&gt;&gt; load_kgx_paths(\"dummy.json\")\n    Traceback (most recent call last):\n        ...\n    NotImplementedError: KGX support not yet implemented\n    \"\"\"\n    with pytest.raises(NotImplementedError):\n        load_kgx_paths(\"dummy.json\")\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>uv run pytest tests/test_kgx.py -v</code></p> <p>Expected: FAIL with \"ImportError: cannot import name 'load_kgx_paths'\"</p> <p>Step 3: Write minimal implementation</p> <p>Create file <code>src/path_embedding/data/kgx.py</code>:</p> <pre><code>\"\"\"KGX format data loading (stub for future implementation).\n\nKGX (Knowledge Graph Exchange) format support will be added in a future version.\nThis module provides stubs to document the planned interface.\n\nExpected KGX format:\n- Nodes: JSON/TSV with id, category, name fields\n- Edges: JSON/TSV with subject, predicate, object fields\n\nFuture implementation will:\n1. Load KGX nodes and edges\n2. Construct paths from edge sequences\n3. Convert to Path objects matching DrugMechDB format\n\"\"\"\nfrom typing import List\nfrom path_embedding.datamodel.types import Path\n\n\ndef load_kgx_paths(file_path: str) -&gt; List[Path]:\n    \"\"\"Load paths from KGX format file.\n\n    Args:\n        file_path: Path to KGX JSON or TSV file\n\n    Returns:\n        List of Path objects\n\n    Raises:\n        NotImplementedError: KGX support not yet implemented\n\n    Example:\n        &gt;&gt;&gt; load_kgx_paths(\"paths.kgx.json\")\n        Traceback (most recent call last):\n            ...\n        NotImplementedError: KGX support not yet implemented\n    \"\"\"\n    raise NotImplementedError(\"KGX support not yet implemented\")\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>uv run pytest tests/test_kgx.py -v</code></p> <p>Expected: PASS</p> <p>Step 5: Run doctests</p> <p>Run: <code>uv run pytest tests/test_kgx.py --doctest-modules</code></p> <p>Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add src/path_embedding/data/kgx.py tests/test_kgx.py\ngit commit -m \"feat: add KGX loader stub for future implementation\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#final-steps","title":"Final Steps","text":""},{"location":"plans/2025-11-10-path-embedding-implementation/#task-91-run-full-test-suite","title":"Task 9.1: Run Full Test Suite","text":"<p>Step 1: Run all tests</p> <p>Run: <code>just test</code></p> <p>Expected: All tests pass, type checking passes, formatting passes</p> <p>Step 2: If any failures, fix them</p> <p>Address any test failures, type errors, or formatting issues.</p> <p>Step 3: Commit fixes</p> <pre><code>git add .\ngit commit -m \"fix: address test/typing/formatting issues\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-92-create-data-and-models-directories","title":"Task 9.2: Create Data and Models Directories","text":"<p>Step 1: Create directories</p> <p>Run:</p> <pre><code>mkdir -p data models\necho \"# DrugMechDB data files\" &gt; data/README.md\necho \"# Trained models\" &gt; models/README.md\n</code></pre> <p>Step 2: Add to git</p> <pre><code>git add data/README.md models/README.md\ngit commit -m \"chore: add data and models directories\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#task-93-update-documentation","title":"Task 9.3: Update Documentation","text":"<p>Step 1: Verify README is up to date</p> <p>Check that <code>README.md</code> matches what was written earlier.</p> <p>Step 2: Verify design doc is complete</p> <p>Check <code>docs/plans/2025-11-10-path-embedding-classifier-design.md</code></p> <p>Step 3: Add usage examples to docs</p> <p>Create <code>docs/usage.md</code> with examples of how to use the CLI.</p> <p>Step 4: Commit</p> <pre><code>git add docs/\ngit commit -m \"docs: add usage examples\"\n</code></pre>"},{"location":"plans/2025-11-10-path-embedding-implementation/#success-criteria","title":"Success Criteria","text":"<p>After completing all tasks:</p> <ul> <li>[ ] All tests pass: <code>just test</code></li> <li>[ ] Type checking passes: <code>just mypy</code></li> <li>[ ] Formatting passes: <code>just format</code></li> <li>[ ] Can train model: <code>uv run path-embedding train --data &lt;file&gt; --output model.pkl</code></li> <li>[ ] Model saves successfully</li> <li>[ ] Evaluation metrics printed</li> <li>[ ] README updated</li> <li>[ ] Design document complete</li> <li>[ ] All commits made with clear messages</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-implementation/#notes","title":"Notes","text":"<ul> <li>API Costs: The embedding generation makes real OpenAI API calls. Use small test datasets during development to minimize costs.</li> <li>Test Data: The <code>tests/data/sample_drugmechdb.yaml</code> fixture contains only 2 indications. For real training, download the full DrugMechDB YAML file.</li> <li>Random Seeds: All random operations use seeds for reproducibility (42 default).</li> <li>Future Work: KGX support, node enrichment, alternative classifiers are noted but not implemented.</li> </ul>"},{"location":"plans/2025-11-10-path-embedding-implementation/#execution","title":"Execution","text":"<p>Plan complete and saved to <code>docs/plans/2025-11-10-path-embedding-implementation.md</code>.</p> <p>Two execution options:</p> <p>1. Subagent-Driven (this session) - I dispatch fresh subagent per task, review between tasks, fast iteration</p> <p>2. Parallel Session (separate) - Open new session with executing-plans, batch execution with checkpoints</p> <p>Which approach?</p>"},{"location":"plans/2025-11-11-hard-negatives-design/","title":"Hard Negatives Experiment Design","text":"<p>Date: 2025-11-11 Purpose: Create more challenging negative examples by replacing only one node instead of shuffling all intermediate nodes</p>"},{"location":"plans/2025-11-11-hard-negatives-design/#background","title":"Background","text":"<p>Current negative sampling (<code>generate_negatives()</code>) replaces all intermediate nodes with nodes from different disease contexts. This creates very obviously wrong paths.</p> <p>This experiment tests whether replacing just one node creates harder negatives that force the model to learn more subtle distinctions.</p>"},{"location":"plans/2025-11-11-hard-negatives-design/#design-decisions","title":"Design Decisions","text":""},{"location":"plans/2025-11-11-hard-negatives-design/#1-node-selection-strategy","title":"1. Node Selection Strategy","text":"<ul> <li>Random intermediate node - Select one random non-Drug/non-Disease node</li> <li>Simple, unbiased approach</li> <li>Creates variety in what gets changed</li> </ul>"},{"location":"plans/2025-11-11-hard-negatives-design/#2-collision-avoidance","title":"2. Collision Avoidance","text":"<ul> <li>Check against extracted positive paths - Compare generated path text against all known positives</li> <li>Fast O(1) lookup using set</li> <li>Retry with different random node if collision detected (max 10 attempts)</li> <li>Fall back to full shuffle if all retries fail</li> </ul>"},{"location":"plans/2025-11-11-hard-negatives-design/#3-replacement-strategy","title":"3. Replacement Strategy","text":"<ul> <li>Sample from different disease context - Replace with node of same type from different disease</li> <li>Reuses existing <code>build_node_inventory()</code> structure</li> <li>Different disease context helps ensure implausibility</li> <li>Single-node change makes it \"hard\" regardless</li> </ul>"},{"location":"plans/2025-11-11-hard-negatives-design/#4-code-integration","title":"4. Code Integration","text":"<ul> <li>New function alongside existing - Create <code>generate_hard_negatives()</code></li> <li>Keeps both approaches available for comparison</li> <li>Separate experiment notebook to evaluate both</li> </ul>"},{"location":"plans/2025-11-11-hard-negatives-design/#implementation","title":"Implementation","text":""},{"location":"plans/2025-11-11-hard-negatives-design/#new-function-generate_hard_negative_path","title":"New Function: <code>generate_hard_negative_path()</code>","text":"<pre><code>def generate_hard_negative_path(\n    positive_path: Path,\n    node_inventory: Dict[str, Dict[str, List[Node]]],\n    all_positive_texts: set[str],\n    max_retries: int = 10\n) -&gt; Path\n</code></pre> <p>Algorithm: 1. Get all intermediate nodes (exclude Drug/Disease) 2. If no intermediate nodes, fall back to full shuffle 3. Randomly select one intermediate node position 4. For up to <code>max_retries</code> attempts:    - Replace selected node with random node of same type from different disease    - Convert path to text using <code>path_to_text()</code>    - Check if text in <code>all_positive_texts</code>    - If not found: return this negative path 5. If all retries fail: fall back to <code>generate_negative_path()</code> (full shuffle)</p> <p>Why retry limit of 10? - Single-node changes are unlikely to collide with real paths - 10 retries gives high probability of finding non-colliding path - Fallback ensures we always get a negative example</p>"},{"location":"plans/2025-11-11-hard-negatives-design/#new-function-generate_hard_negatives","title":"New Function: <code>generate_hard_negatives()</code>","text":"<pre><code>def generate_hard_negatives(positive_paths: List[Path]) -&gt; List[Path]\n</code></pre> <p>Algorithm: 1. Build node inventory using existing <code>build_node_inventory()</code> 2. Pre-compute set of all positive path texts for collision detection 3. For each positive path, generate one hard negative 4. Returns list of negative paths (maintains 1:1 ratio)</p>"},{"location":"plans/2025-11-11-hard-negatives-design/#experiment-design","title":"Experiment Design","text":""},{"location":"plans/2025-11-11-hard-negatives-design/#notebook-notebookshard_negatives_experimentipynb","title":"Notebook: <code>notebooks/hard_negatives_experiment.ipynb</code>","text":"<p>Structure:</p> <ol> <li>Setup &amp; Data Loading</li> <li>Load DrugMechDB data</li> <li>Extract paths from multigraphs</li> <li> <p>Split train/test by indication</p> </li> <li> <p>Experiment 1: Standard Negatives (Baseline)</p> </li> <li>Generate negatives with <code>generate_negatives()</code> (shuffle all nodes)</li> <li>Train Random Forest + OpenAI embeddings</li> <li>Train Logistic Regression + TF-IDF</li> <li> <p>Record metrics (accuracy, precision, recall, F1, ROC-AUC)</p> </li> <li> <p>Experiment 2: Hard Negatives</p> </li> <li>Generate negatives with <code>generate_hard_negatives()</code> (replace one node)</li> <li>Train same two models</li> <li> <p>Record same metrics</p> </li> <li> <p>Comparison &amp; Analysis</p> </li> <li>Side-by-side metrics comparison table</li> <li>Visualizations showing performance differences</li> <li>Error analysis: which negatives are harder to classify?</li> <li>Example comparisons of standard vs hard negatives</li> <li>Statistical significance testing</li> </ol> <p>Expected Outcomes:</p> <ul> <li>Hard negatives hypothesis: Lower accuracy but more robust learning</li> <li>Model discrimination: May reveal which model better captures mechanistic understanding</li> <li>Error patterns: Hard negatives should have lower confidence scores</li> </ul>"},{"location":"plans/2025-11-11-hard-negatives-design/#testing","title":"Testing","text":"<p>Add tests to <code>tests/test_negative_sampling.py</code>:</p> <ol> <li>Test single-node difference:</li> <li>Verify hard negative differs from positive by exactly one intermediate node</li> <li> <p>Drug and Disease nodes remain unchanged</p> </li> <li> <p>Test collision detection:</p> </li> <li>Verify function rejects paths that match existing positives</li> <li> <p>Verify retry mechanism works</p> </li> <li> <p>Test fallback behavior:</p> </li> <li>When retries exhausted, falls back to full shuffle</li> <li> <p>When no intermediate nodes exist, falls back to full shuffle</p> </li> <li> <p>Test node type preservation:</p> </li> <li>Replacement node has same label as original node</li> </ol>"},{"location":"plans/2025-11-11-hard-negatives-design/#success-criteria","title":"Success Criteria","text":"<ol> <li>Function generates valid hard negatives (one node different)</li> <li>No false negatives (real paths labeled as negative)</li> <li>Experiment notebook runs end-to-end</li> <li>Results clearly show difficulty difference between standard and hard negatives</li> <li>All tests pass</li> </ol>"},{"location":"plans/2025-11-11-hard-negatives-design/#files-to-createmodify","title":"Files to Create/Modify","text":"<p>New files: - <code>notebooks/hard_negatives_experiment.ipynb</code></p> <p>Modified files: - <code>src/path_embedding/data/negative_sampling.py</code> - Add <code>generate_hard_negative_path()</code> and <code>generate_hard_negatives()</code> - <code>tests/test_negative_sampling.py</code> - Add tests for new functions</p>"},{"location":"plans/2025-11-11-hard-negatives-design/#open-questions","title":"Open Questions","text":"<p>None - design is complete and validated.</p>"}]}